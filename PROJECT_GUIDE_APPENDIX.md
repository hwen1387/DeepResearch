# Tongyi DeepResearch é¡¹ç›®æŒ‡å— - é™„å½•

> æœ¬æ–‡æ¡£æ˜¯ PROJECT_GUIDE_CN.md çš„è¡¥å……ï¼ŒåŒ…å«åç»­ç« èŠ‚

---

## 7. å¼€å‘æŒ‡å—

### 7.1 é¡¹ç›®ç»“æ„å¯¼èˆª

```
DeepResearch/
â”‚
â”œâ”€â”€ ğŸ“‚ inference/                        # ã€æ ¸å¿ƒã€‘ä¸»æ¨ç†å¼•æ“
â”‚   â”œâ”€â”€ react_agent.py                   # ReAct ä»£ç†æ ¸å¿ƒ (248 è¡Œ)
â”‚   â”œâ”€â”€ run_multi_react.py               # å¤šçº¿ç¨‹ç¼–æ’å™¨ (228 è¡Œ)
â”‚   â”œâ”€â”€ prompt.py                        # ç³»ç»Ÿæç¤ºè¯
â”‚   â”œâ”€â”€ tool_search.py                   # æœç´¢å·¥å…·
â”‚   â”œâ”€â”€ tool_visit.py                    # ç½‘é¡µè®¿é—®å·¥å…·
â”‚   â”œâ”€â”€ tool_file.py                     # æ–‡ä»¶è§£æå·¥å…·
â”‚   â”œâ”€â”€ tool_python.py                   # Python è§£é‡Šå™¨
â”‚   â”œâ”€â”€ tool_scholar.py                  # å­¦æœ¯æœç´¢å·¥å…·
â”‚   â”œâ”€â”€ file_tools/                      # æ–‡ä»¶è§£æå­ç³»ç»Ÿ
â”‚   â”‚   â”œâ”€â”€ file_parser.py               # æ–‡æ¡£è§£æå™¨
â”‚   â”‚   â”œâ”€â”€ idp.py                       # Alibaba IDP é›†æˆ
â”‚   â”‚   â”œâ”€â”€ video_agent.py               # éŸ³è§†é¢‘å¤„ç†
â”‚   â”‚   â””â”€â”€ utils.py                     # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ eval_data/                       # è¯„ä¼°æ•°æ®
â”‚   â”‚   â”œâ”€â”€ file_corpus/                 # å¼•ç”¨æ–‡ä»¶å­˜æ”¾å¤„
â”‚   â”‚   â””â”€â”€ *.jsonl                      # æŸ¥è¯¢æ•°æ®é›†
â”‚   â””â”€â”€ run_react_infer.sh               # å¯åŠ¨è„šæœ¬
â”‚
â”œâ”€â”€ ğŸ“‚ WebAgent/                         # ã€æ‰©å±•ã€‘ä¸“ä¸šä»£ç†å®¶æ—
â”‚   â”œâ”€â”€ NestBrowse/                      # æµè§ˆå™¨ä»£ç† (å¼‚æ­¥ + MCP)
â”‚   â”‚   â”œâ”€â”€ infer_async_nestbrowse.py    # ä¸»æ‰§è¡Œæ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ toolkit/                     # å·¥å…·é›†
â”‚   â”‚   â”‚   â”œâ”€â”€ browser.py               # Visit/Click/Fill
â”‚   â”‚   â”‚   â”œâ”€â”€ mcp_client.py            # MCP åè®®å®¢æˆ·ç«¯
â”‚   â”‚   â”‚   â””â”€â”€ tool_search.py           # æœç´¢å·¥å…·
â”‚   â”‚   â””â”€â”€ prompts.py                   # æç¤ºè¯
â”‚   â”‚
â”‚   â”œâ”€â”€ ParallelMuse/                    # å¹¶è¡Œè½¨è¿¹èšåˆ
â”‚   â”‚   â”œâ”€â”€ compressed_reasoning_aggregation.py
â”‚   â”‚   â””â”€â”€ prompts.py
â”‚   â”‚
â”‚   â”œâ”€â”€ WebDancer/                       # åŸç”Ÿæœç´¢ä»£ç† (NeurIPS 2025)
â”‚   â”œâ”€â”€ WebSailor/                       # è¶…äººæ¨ç† + DUPO RL
â”‚   â”œâ”€â”€ WebWatcher/                      # è§†è§‰è¯­è¨€ä»£ç†
â”‚   â”œâ”€â”€ WebShaper/                       # æ•°æ®åˆæˆ
â”‚   â”œâ”€â”€ WebWeaver/                       # è¯æ®ç»“æ„åŒ–
â”‚   â”œâ”€â”€ WebResearcher/                   # é•¿è§†é‡æ¨ç†
â”‚   â”œâ”€â”€ WebResummer/                     # ä¸Šä¸‹æ–‡æ‘˜è¦
â”‚   â””â”€â”€ WebLeaper/                       # ä¿¡æ¯è·³è·ƒ
â”‚
â”œâ”€â”€ ğŸ“‚ Agent/                            # ã€è®­ç»ƒã€‘ä»£ç†è®­ç»ƒåŸºç¡€è®¾æ–½
â”‚   â”œâ”€â”€ AgentScaler/                     # æŒç»­é¢„è®­ç»ƒæ¡†æ¶
â”‚   â””â”€â”€ AgentFounder/                    # è®­ç»ƒåŸºç¡€
â”‚
â”œâ”€â”€ ğŸ“‚ evaluation/                       # ã€è¯„ä¼°ã€‘åŸºå‡†æµ‹è¯•
â”‚   â”œâ”€â”€ evaluate_deepsearch_official.py  # DeepSearch åŸºå‡†
â”‚   â”œâ”€â”€ evaluate_hle_official.py         # HLE åŸºå‡†
â”‚   â””â”€â”€ prompt.py                        # è¯„åˆ¤æç¤ºè¯
â”‚
â”œâ”€â”€ ğŸ“„ .env.example                      # ç¯å¢ƒé…ç½®æ¨¡æ¿
â”œâ”€â”€ ğŸ“„ requirements.txt                  # Python ä¾èµ–
â”œâ”€â”€ ğŸ“„ README.md                         # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ ğŸ“„ FAQ.md                            # å¸¸è§é—®é¢˜
â”œâ”€â”€ ğŸ“„ CLAUDE.md                         # Claude Code æŒ‡å—
â”œâ”€â”€ ğŸ“„ ARCHITECTURE_CN.md                # æ¶æ„åˆ†ææ–‡æ¡£
â””â”€â”€ ğŸ“„ PROJECT_GUIDE_CN.md               # æœ¬é¡¹ç›®æŒ‡å—
```

### 7.2 å…³é”®æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | è¡Œæ•° | æ ¸å¿ƒåŠŸèƒ½ | ä½•æ—¶ä¿®æ”¹ |
|-----|------|---------|---------|
| `inference/react_agent.py` | 248 | ReAct ä¸»å¾ªç¯ | ä¿®æ”¹ä»£ç†è¡Œä¸ºã€å·¥å…·è°ƒç”¨é€»è¾‘ |
| `inference/run_multi_react.py` | 228 | å¤šçº¿ç¨‹ç¼–æ’ | ä¿®æ”¹å¹¶å‘ç­–ç•¥ã€æ£€æŸ¥ç‚¹é€»è¾‘ |
| `inference/prompt.py` | 52 | ç³»ç»Ÿæç¤ºè¯ | ä¿®æ”¹ä»£ç†æŒ‡ä»¤ã€å·¥å…·å®šä¹‰ |
| `inference/tool_*.py` | 100-250 | å„å·¥å…·å®ç° | æ·»åŠ /ä¿®æ”¹å·¥å…·åŠŸèƒ½ |
| `inference/run_react_infer.sh` | 118 | å¯åŠ¨è„šæœ¬ | ä¿®æ”¹æœåŠ¡å™¨é…ç½®ã€ç«¯å£ |
| `evaluation/evaluate_*.py` | 200+ | è¯„ä¼°è„šæœ¬ | æ·»åŠ æ–°åŸºå‡†ã€ä¿®æ”¹è¯„åˆ¤é€»è¾‘ |

### 7.3 å¼€å‘å·¥ä½œæµ

#### æœ¬åœ°å¼€å‘ç¯å¢ƒ

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/Alibaba-NLP/DeepResearch.git
cd DeepResearch

# 2. åˆ›å»ºå¼€å‘åˆ†æ”¯
git checkout -b feature/my-new-feature

# 3. å®‰è£…ä¾èµ– (å¼€å‘æ¨¡å¼)
pip install -e .
pip install -r requirements-dev.txt  # å¦‚æœæœ‰å¼€å‘ä¾èµ–

# 4. é…ç½®ç¯å¢ƒ
cp .env.example .env
vim .env  # å¡«å†™ API keys

# 5. è¿è¡Œæµ‹è¯•
pytest tests/  # å¦‚æœæœ‰æµ‹è¯•
```

#### ä»£ç ä¿®æ”¹ç¤ºä¾‹

**åœºæ™¯: ä¿®æ”¹æœç´¢å·¥å…·ï¼Œæ·»åŠ æ—¥æœŸè¿‡æ»¤**

```bash
# 1. ç¼–è¾‘å·¥å…·æ–‡ä»¶
vim inference/tool_search.py

# ä¿®æ”¹ Search.call() æ–¹æ³•
def call(self, params: str, **kwargs) -> str:
    params_dict = json.loads(params)
    query_list = params_dict['query']
    date_filter = params_dict.get('date_filter', None)  # æ–°å¢å‚æ•°

    results = []
    for query in query_list:
        # æ·»åŠ æ—¥æœŸè¿‡æ»¤é€»è¾‘
        if date_filter:
            query += f" after:{date_filter}"
        result = self.google_search_with_serp([query])
        results.append(result)

    return '\n\n'.join(results)

# 2. æ›´æ–°å·¥å…·æè¿° (prompt.py)
vim inference/prompt.py

# åœ¨ SYSTEM_PROMPT ä¸­æ·»åŠ  date_filter å‚æ•°è¯´æ˜
{"type": "function", "function": {
    "name": "search",
    "parameters": {
        ...
        "date_filter": {
            "type": "string",
            "description": "æ—¥æœŸè¿‡æ»¤ï¼Œæ ¼å¼: YYYY-MM-DD"
        }
    }
}}

# 3. æµ‹è¯•ä¿®æ”¹
cat > eval_data/test_date_filter.jsonl << EOF
{"question": "æœç´¢ 2024 å¹´ä¹‹åå…³äºé‡å­è®¡ç®—çš„æ–°é—»", "answer": ""}
EOF

python inference/run_multi_react.py \
    --model $MODEL_PATH \
    --dataset eval_data/test_date_filter.jsonl \
    --output outputs/test \
    --max_workers 1

# 4. æŸ¥çœ‹ç»“æœ
cat outputs/test/*.jsonl | jq '.messages[] | select(.role == "user" and (.content | contains("<tool_response>")))'

# 5. æäº¤æ›´æ”¹
git add inference/tool_search.py inference/prompt.py
git commit -m "feat: ä¸ºæœç´¢å·¥å…·æ·»åŠ æ—¥æœŸè¿‡æ»¤åŠŸèƒ½"
git push origin feature/my-new-feature
```

### 7.4 è°ƒè¯•æŠ€å·§

#### æ‰“å°è°ƒè¯•ä¿¡æ¯

åœ¨ `react_agent.py` ä¸­æ·»åŠ è°ƒè¯•è¾“å‡ºï¼š

```python
# åœ¨ _run() æ–¹æ³•ä¸­
def _run(self, data, model, planning_port):
    print(f"[DEBUG] å¤„ç†é—®é¢˜: {data['question'][:50]}...")

    for turn in range(MAX_LLM_CALL_PER_RUN):
        print(f"[DEBUG] ç¬¬ {turn+1} è½®å¼€å§‹")

        response = self.call_server(messages, planning_port)
        print(f"[DEBUG] LLM å“åº”é•¿åº¦: {len(response)} å­—ç¬¦")

        if "<tool_call>" in response:
            tool_calls = extract_tool_calls(response)
            print(f"[DEBUG] æå–åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")

            for tc in tool_calls:
                print(f"[DEBUG] è°ƒç”¨å·¥å…·: {tc['name']}")
                result = self.custom_call_tool(tc['name'], tc['arguments'])
                print(f"[DEBUG] å·¥å…·è¿”å›é•¿åº¦: {len(result)} å­—ç¬¦")
```

#### ä¿å­˜ä¸­é—´ç»“æœ

```python
# åœ¨ä¸»å¾ªç¯ä¸­ä¿å­˜æ¯è½®çš„æ¶ˆæ¯
import json
import os

debug_dir = "debug_output"
os.makedirs(debug_dir, exist_ok=True)

for turn in range(MAX_LLM_CALL_PER_RUN):
    # ... æ‰§è¡Œé€»è¾‘ ...

    # ä¿å­˜å½“å‰çŠ¶æ€
    with open(f"{debug_dir}/turn_{turn}.json", 'w') as f:
        json.dump({
            'turn': turn,
            'messages': messages,
            'token_count': get_token_count(messages)
        }, f, indent=2, ensure_ascii=False)
```

#### ä½¿ç”¨ Python è°ƒè¯•å™¨

```python
# åœ¨å…³é”®ä½ç½®è®¾ç½®æ–­ç‚¹
import pdb

def custom_call_tool(self, tool_name, tool_args):
    if tool_name == "visit":  # åªåœ¨ visit å·¥å…·æ—¶æ–­ç‚¹
        pdb.set_trace()

    tool = TOOL_MAP.get(tool_name)
    ...
```

#### æ—¥å¿—è®°å½•

```python
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('deepresearch.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# åœ¨ä»£ç ä¸­ä½¿ç”¨
logger.info(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")
logger.debug(f"å·¥å…·å‚æ•°: {params}")
logger.warning(f"ä¸Šä¸‹æ–‡é•¿åº¦æ¥è¿‘ä¸Šé™: {token_count}/110000")
logger.error(f"å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
```

---

## 8. å¸¸è§é—®é¢˜

### 8.1 å®‰è£…å’Œé…ç½®é—®é¢˜

#### Q: pip install å‡ºç°ä¾èµ–å†²çª

**A:** ä½¿ç”¨ Python 3.10.0 å¹¶åˆ›å»ºå¹²å‡€çš„è™šæ‹Ÿç¯å¢ƒ

```bash
# ç¡®è®¤ Python ç‰ˆæœ¬
python --version  # å¿…é¡»æ˜¯ 3.10.0

# åˆ é™¤æ—§ç¯å¢ƒ
conda env remove -n react_infer_env

# é‡æ–°åˆ›å»º
conda create -n react_infer_env python=3.10.0
conda activate react_infer_env

# å‡çº§ pip
pip install --upgrade pip

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### Q: vLLM å¯åŠ¨å¤±è´¥ï¼ŒæŠ¥ CUDA é”™è¯¯

**A:** æ£€æŸ¥ CUDA ç‰ˆæœ¬å’Œ GPU é©±åŠ¨

```bash
# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# æ£€æŸ¥ GPU çŠ¶æ€
nvidia-smi

# ç¡®ä¿ CUDA 12.0+
# å¦‚æœç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦å‡çº§ CUDA toolkit

# é‡æ–°å®‰è£… vLLM
pip uninstall vllm
pip install vllm --no-cache-dir
```

#### Q: API Key é…ç½®åä»ç„¶æŠ¥é”™

**A:** æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦æ­£ç¡®åŠ è½½

```bash
# ç¡®è®¤ .env æ–‡ä»¶å­˜åœ¨
ls -la .env

# æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦åŠ è½½
python -c "import os; from dotenv import load_dotenv; load_dotenv(); print(os.getenv('SERPER_KEY_ID'))"

# å¦‚æœè¿”å› Noneï¼Œæ‰‹åŠ¨åŠ è½½
export $(cat .env | xargs)

# æˆ–åœ¨ä»£ç ä¸­æ˜ç¡®åŠ è½½
# react_agent.py å¼€å¤´æ·»åŠ :
from dotenv import load_dotenv
load_dotenv()
```

### 8.2 è¿è¡Œæ—¶é—®é¢˜

#### Q: æ¨ç†è¿‡ç¨‹ä¸­å‡ºç° "context_length_exceeded"

**A:** ä¼˜åŒ–ä¸Šä¸‹æ–‡ç®¡ç†

```python
# æ–¹æ¡ˆ 1: å¢åŠ ä¸Šä¸‹æ–‡æˆªæ–­é˜ˆå€¼ (è°¨æ…)
# react_agent.py:195
if get_token_count(messages) > 120000:  # ä» 110000 å¢åŠ åˆ° 120000

# æ–¹æ¡ˆ 2: å®ç°ä¸Šä¸‹æ–‡å‹ç¼© (æ¨è)
def compress_context(messages, max_length=110000):
    """å‹ç¼©æ¶ˆæ¯å†å²"""
    current_length = get_token_count(messages)

    if current_length <= max_length:
        return messages

    # ä¿ç•™ system æ¶ˆæ¯å’Œæœ€è¿‘çš„ N è½®å¯¹è¯
    system_msg = messages[0]
    recent_messages = messages[-20:]  # ä¿ç•™æœ€è¿‘ 20 æ¡

    # æ‘˜è¦ä¸­é—´éƒ¨åˆ†
    middle_messages = messages[1:-20]
    summary = summarize_messages(middle_messages)

    return [system_msg, {"role": "user", "content": f"[ä¹‹å‰çš„å¯¹è¯æ‘˜è¦]\n{summary}"}] + recent_messages

# åœ¨ä¸»å¾ªç¯ä¸­ä½¿ç”¨
messages = compress_context(messages)
```

#### Q: å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œè¿”å›é”™è¯¯

**A:** æ·»åŠ é‡è¯•å’Œé”™è¯¯å¤„ç†

```python
# åœ¨ custom_call_tool ä¸­
def custom_call_tool(self, tool_name, tool_args):
    max_retries = 3
    for attempt in range(max_retries):
        try:
            tool = TOOL_MAP.get(tool_name)
            if not tool:
                return f"é”™è¯¯: æœªçŸ¥å·¥å…· '{tool_name}'"

            result = tool.call(tool_args)

            # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰æ•ˆ
            if result and len(result) > 0:
                return result

        except Exception as e:
            logger.error(f"å·¥å…· {tool_name} è°ƒç”¨å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {e}")

            if attempt == max_retries - 1:
                return f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"

            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

#### Q: æ¨ç†é€Ÿåº¦å¾ˆæ…¢

**A:** å¤šæ–¹é¢ä¼˜åŒ–

```bash
# 1. å¢åŠ å¹¶å‘åº¦
--max_workers 50  # æ ¹æ® GPU æ•°é‡è°ƒæ•´

# 2. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹è¿›è¡Œæ‘˜è¦
# .env ä¸­:
SUMMARY_MODEL_NAME=gpt-3.5-turbo  # æ›¿ä»£ gpt-4

# 3. å¯ç”¨ç¼“å­˜
pip install diskcache

# åœ¨ tool_search.py ä¸­:
from diskcache import Cache
cache = Cache('.cache/search_results')

@cache.memoize(expire=3600)  # 1 å°æ—¶ç¼“å­˜
def google_search_with_serp(query_list, api_key):
    ...

# 4. å‡å°‘ vLLM æ¨ç†å»¶è¿Ÿ
vllm serve $MODEL_PATH \
    --max-num-seqs 8 \  # å¢åŠ æ‰¹å¤„ç†å¤§å°
    --enable-prefix-caching \  # å¯ç”¨å‰ç¼€ç¼“å­˜
    --gpu-memory-utilization 0.95  # æé«˜ GPU åˆ©ç”¨ç‡
```

### 8.3 ç»“æœè´¨é‡é—®é¢˜

#### Q: æ¨¡å‹å›ç­”ä¸å‡†ç¡®æˆ–ä¸å®Œæ•´

**A:** è°ƒæ•´æç¤ºè¯å’Œå‚æ•°

```python
# 1. å¢å¼ºç³»ç»Ÿæç¤ºè¯
SYSTEM_PROMPT = """
You are a deep research assistant. Your core function is...

# Important Guidelines
1. ALWAYS use multiple tools to verify information
2. Cross-reference facts from at least 2-3 sources
3. Explicitly state when information is uncertain
4. Provide detailed reasoning in <think> tags
5. Only give final answer when you have high confidence

...
"""

# 2. è°ƒæ•´é‡‡æ ·å‚æ•°
# æ›´ç¡®å®šæ€§çš„ç”Ÿæˆ
--temperature 0.3 --presence_penalty 0.8

# æˆ–ä½¿ç”¨ multiple rollouts + voting
--roll_out_count 5

# ç„¶åé€‰æ‹© majority vote ç­”æ¡ˆ
```

#### Q: æ¨¡å‹ä¸ä½¿ç”¨å·¥å…·æˆ–ä½¿ç”¨é”™è¯¯çš„å·¥å…·

**A:** ä¼˜åŒ–å·¥å…·æè¿°å’Œç¤ºä¾‹

```python
# åœ¨ prompt.py ä¸­æ·»åŠ è¯¦ç»†æè¿°
{"type": "function", "function": {
    "name": "search",
    "description": """
    æ‰§è¡Œ Google æœç´¢ã€‚

    **ä½•æ—¶ä½¿ç”¨**:
    - æŸ¥æ‰¾æœ€æ–°ä¿¡æ¯ (æ–°é—»ã€äº‹ä»¶ã€æ•°æ®)
    - è·å–å¤šä¸ªä¿¡æ¯æº
    - æ¢ç´¢æ€§ç ”ç©¶

    **è¾“å…¥**: æŸ¥è¯¢å­—ç¬¦ä¸²åˆ—è¡¨
    **è¾“å‡º**: Top 10 æœç´¢ç»“æœ (æ ‡é¢˜ã€URLã€æ‘˜è¦)

    **ç¤ºä¾‹**:
    <tool_call>
    {"name": "search", "arguments": {"query": ["2024 Nobel Prize Physics"]}}
    </tool_call>
    """,
    ...
}}

# æ·»åŠ  Few-Shot ç¤ºä¾‹
SYSTEM_PROMPT += """
# Tool Usage Examples

**Example 1**: Factual Query
User: "Who won the 2024 Nobel Prize in Physics?"
Assistant: <think>I need to search for recent information</think>
<tool_call>{"name": "search", "arguments": {"query": ["2024 Nobel Prize Physics winner"]}}</tool_call>

**Example 2**: Deep Research
User: "Compare GPT-4 and Claude 3"
Assistant: <think>I should search for both and visit official sources</think>
<tool_call>{"name": "search", "arguments": {"query": ["GPT-4 specifications", "Claude 3 capabilities"]}}</tool_call>
...
"""
```

#### Q: ç”Ÿæˆçš„ç­”æ¡ˆåŒ…å«å¹»è§‰ (hallucination)

**A:** å¼ºåŒ–è¯æ®éªŒè¯

```python
# ä¿®æ”¹ SYSTEM_PROMPT
SYSTEM_PROMPT = """
...

# Anti-Hallucination Guidelines
1. **NEVER** make up facts or sources
2. **ALWAYS** cite tool outputs when stating facts
3. Use phrases like "According to [source]..." or "Based on [search result]..."
4. If information cannot be found, explicitly state: "I could not find reliable information about..."
5. Mark uncertain information with qualifiers: "possibly", "likely", "approximately"

# Answer Format
<answer>
[Your answer]

**Sources**:
- [Search] "query" â†’ found at URL
- [Visit] URL â†’ key information extracted
- [Scholar] "paper title" â†’ citation
</answer>
"""
```

### 8.4 è¯„ä¼°é—®é¢˜

#### Q: è¯„ä¼°è„šæœ¬æŠ¥é”™

**A:** æ£€æŸ¥æ•°æ®æ ¼å¼

```bash
# ç¡®è®¤è¾“å‡ºæ–‡ä»¶æ ¼å¼æ­£ç¡®
head -1 outputs/results_rollout_0.jsonl | jq .

# åº”åŒ…å«å­—æ®µ: question, answer, prediction, termination, messages

# å¦‚æœå­—æ®µç¼ºå¤±ï¼Œæ£€æŸ¥ run_multi_react.py çš„è¾“å‡ºé€»è¾‘
```

#### Q: LLM è¯„åˆ¤å™¨ç»“æœä¸ä¸€è‡´

**A:** ä½¿ç”¨å¤šä¸ªè¯„åˆ¤å™¨æŠ•ç¥¨

```python
# evaluation/ensemble_judge.py
def ensemble_judge(question, prediction, reference):
    judges = [
        ('gpt-4', judge_with_gpt4),
        ('claude-3.5', judge_with_claude),
        ('qwen2.5-72b', judge_with_qwen)
    ]

    votes = []
    for name, judge_fn in judges:
        result = judge_fn(question, prediction, reference)
        votes.append(result['correct'])

    # Majority voting
    final_verdict = sum(votes) > len(votes) / 2

    return {
        'correct': final_verdict,
        'individual_votes': dict(zip([j[0] for j in judges], votes))
    }
```

---

## 9. è¿›é˜¶ä¸»é¢˜

### 9.1 è‡ªå®šä¹‰ WebAgent

åˆ›å»ºæ‚¨è‡ªå·±çš„ä¸“ä¸šä»£ç†ï¼š

```bash
# 1. åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir -p WebAgent/MyCustomAgent
cd WebAgent/MyCustomAgent

# 2. åˆ›å»ºæ–‡ä»¶ç»“æ„
touch __init__.py
touch infer_my_agent.py
touch prompts.py
mkdir toolkit
touch toolkit/__init__.py
touch toolkit/tool_custom.py

# 3. å®ç°ä¸»å¾ªç¯ (åŸºäº NestBrowse æ¨¡æ¿)
# infer_my_agent.py
```

**æ¨¡æ¿ä»£ç **:

```python
# infer_my_agent.py
import asyncio
from openai import OpenAI
from prompts import SYSTEM_PROMPT

async def agentic_loop(question, max_turns=100):
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": question}
    ]

    client = OpenAI(api_key="YOUR_KEY", base_url="http://localhost:6001/v1")

    for turn in range(max_turns):
        # è°ƒç”¨ LLM
        response = client.chat.completions.create(
            model="model_name",
            messages=messages
        )

        content = response.choices[0].message.content
        messages.append({"role": "assistant", "content": content})

        # æ£€æŸ¥ç»ˆæ­¢
        if "<answer>" in content:
            return extract_answer(content), messages

        # æ‰§è¡Œå·¥å…·
        if "<tool_call>" in content:
            tool_results = await execute_tools(content)
            messages.append({"role": "user", "content": tool_results})

    return None, messages

async def main():
    question = "Your research question"
    answer, messages = await agentic_loop(question)
    print(f"Answer: {answer}")

if __name__ == '__main__':
    asyncio.run(main())
```

### 9.2 å¼ºåŒ–å­¦ä¹ è®­ç»ƒ

åŸºäº WebSailor çš„ DUPO ç®—æ³•è¿›è¡Œè®­ç»ƒï¼š

```python
# Agent/AgentScaler/dupo_trainer.py
import torch
import torch.nn.functional as F

class DUPOTrainer:
    def __init__(self, policy_model, ref_model, reward_model):
        self.policy = policy_model
        self.ref_model = ref_model
        self.reward_model = reward_model

    def train_step(self, batch_questions):
        """
        DUPO: Duplicating Sampling Policy Optimization

        å¯¹æ¯ä¸ªé—®é¢˜é‡‡æ ·å¤šä¸ªè½¨è¿¹ï¼Œè®¡ç®—ä¼˜åŠ¿å‡½æ•°ï¼Œæ›´æ–°ç­–ç•¥
        """
        all_trajectories = []

        # 1. é‡‡æ ·å¤šä¸ªè½¨è¿¹
        for question in batch_questions:
            trajectories = []
            for _ in range(self.n_samples):
                trajectory = self.rollout(question)
                trajectories.append(trajectory)

            all_trajectories.append(trajectories)

        # 2. è®¡ç®—å¥–åŠ±
        rewards = []
        for trajs in all_trajectories:
            traj_rewards = [self.reward_model(t) for t in trajs]
            rewards.append(traj_rewards)

        # 3. è®¡ç®—ä¼˜åŠ¿ (leave-one-out baseline)
        advantages = []
        for traj_rewards in rewards:
            baseline = (sum(traj_rewards) - traj_rewards[i]) / (len(traj_rewards) - 1)
            adv = [r - baseline for r in traj_rewards]
            advantages.append(adv)

        # 4. ç­–ç•¥æ¢¯åº¦æ›´æ–°
        policy_loss = 0
        for trajs, advs in zip(all_trajectories, advantages):
            for traj, adv in zip(trajs, advs):
                # è®¡ç®— log æ¦‚ç‡
                log_probs = self.policy.compute_log_probs(traj)

                # åŠ æƒæŸå¤±
                policy_loss += -adv * log_probs.sum()

        # 5. åå‘ä¼ æ’­
        policy_loss.backward()
        self.optimizer.step()

        return policy_loss.item()
```

### 9.3 ç”Ÿäº§éƒ¨ç½²

éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒçš„æœ€ä½³å®è·µï¼š

```yaml
# docker-compose.yml
version: '3.8'

services:
  vllm-server-1:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=0
    command: >
      --model /models/deepresearch
      --host 0.0.0.0
      --port 6001
      --max-num-seqs 16
      --gpu-memory-utilization 0.95
    volumes:
      - ./models:/models
    ports:
      - "6001:6001"

  vllm-server-2:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    environment:
      - CUDA_VISIBLE_DEVICES=1
    command: >
      --model /models/deepresearch
      --host 0.0.0.0
      --port 6002
    volumes:
      - ./models:/models
    ports:
      - "6002:6002"

  agent-service:
    build: .
    depends_on:
      - vllm-server-1
      - vllm-server-2
    environment:
      - SERPER_KEY_ID=${SERPER_KEY_ID}
      - JINA_API_KEYS=${JINA_API_KEYS}
      - API_KEY=${API_KEY}
    volumes:
      - ./inference:/app/inference
      - ./outputs:/app/outputs
    command: python run_api_server.py

  nginx:
    image: nginx:latest
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - agent-service
```

**API æœåŠ¡å™¨ç¤ºä¾‹** (`run_api_server.py`):

```python
from fastapi import FastAPI, BackgroundTasks
from pydantic import BaseModel
from inference.react_agent import MultiTurnReactAgent

app = FastAPI()

class QueryRequest(BaseModel):
    question: str
    max_turns: int = 100

class QueryResponse(BaseModel):
    task_id: str
    status: str

# ä»»åŠ¡é˜Ÿåˆ—
task_queue = {}

@app.post("/query", response_model=QueryResponse)
async def submit_query(request: QueryRequest, background_tasks: BackgroundTasks):
    task_id = generate_task_id()

    task_queue[task_id] = {"status": "pending"}

    # åå°æ‰§è¡Œ
    background_tasks.add_task(run_agent, task_id, request.question, request.max_turns)

    return QueryResponse(task_id=task_id, status="submitted")

@app.get("/result/{task_id}")
async def get_result(task_id: str):
    if task_id not in task_queue:
        return {"error": "Task not found"}

    task = task_queue[task_id]

    if task["status"] == "pending":
        return {"status": "processing"}
    elif task["status"] == "completed":
        return {"status": "completed", "answer": task["answer"], "messages": task["messages"]}
    else:
        return {"status": "failed", "error": task["error"]}

def run_agent(task_id, question, max_turns):
    try:
        agent = MultiTurnReactAgent(...)
        messages, prediction, termination = agent._run(
            {"question": question},
            model="deepresearch",
            planning_port=6001
        )

        task_queue[task_id] = {
            "status": "completed",
            "answer": prediction,
            "messages": messages
        }
    except Exception as e:
        task_queue[task_id] = {
            "status": "failed",
            "error": str(e)
        }
```

---

## 10. æ€»ç»“

### 10.1 Tongyi DeepResearch çš„ä¼˜åŠ¿

âœ… **é•¿è§†é‡æ¨ç†**: æœ€å¤š 100 è½®äº¤äº’ï¼Œ150 åˆ†é’Ÿæ¨ç†æ—¶é—´
âœ… **å¤šæºä¿¡æ¯æ•´åˆ**: ç½‘ç»œã€å­¦æœ¯ã€æ–‡æ¡£ã€ä»£ç æ‰§è¡Œ
âœ… **SOTA æ€§èƒ½**: åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­é¢†å…ˆ
âœ… **å¯æ‰©å±•æ€§**: ä¸°å¯Œçš„ WebAgent å®¶æ—ï¼Œæ˜“äºå®šåˆ¶
âœ… **å¼€æº**: å®Œæ•´çš„ä»£ç ã€æ•°æ®åˆæˆæ–¹æ³•ã€è®­ç»ƒæµç¨‹

### 10.2 æœ€ä½³ä½¿ç”¨åœºæ™¯

ğŸ¯ **å­¦æœ¯ç ”ç©¶**: æ–‡çŒ®ç»¼è¿°ã€è®ºæ–‡è°ƒç ”
ğŸ¯ **å¸‚åœºåˆ†æ**: ç«å“åˆ†æã€è¡Œä¸šæŠ¥å‘Š
ğŸ¯ **æ•°æ®åˆ†æ**: æ–‡ä»¶è§£æã€ç»Ÿè®¡è®¡ç®—ã€å¯è§†åŒ–
ğŸ¯ **ä¿¡æ¯éªŒè¯**: å¤šæºäº¤å‰éªŒè¯ã€äº‹å®æ ¸æŸ¥
ğŸ¯ **å¤æ‚æŸ¥è¯¢**: å¤šè·³æ¨ç†ã€é•¿å°¾é—®é¢˜

### 10.3 å­¦ä¹ èµ„æº

ğŸ“š **è®ºæ–‡**: [Tongyi DeepResearch Technical Report](https://arxiv.org/pdf/2510.24701)
ğŸ“š **åšå®¢**: [å®˜æ–¹æŠ€æœ¯åšå®¢](https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/)
ğŸ“š **æ¨¡å‹**: [HuggingFace](https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B) | [ModelScope](https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B)
ğŸ“š **WebAgent ç³»åˆ—**: 13+ ä¸“ä¸šè®ºæ–‡ (è§ README.md)

### 10.4 ç¤¾åŒºæ”¯æŒ

ğŸ’¬ **GitHub Issues**: [æäº¤é—®é¢˜](https://github.com/Alibaba-NLP/DeepResearch/issues)
ğŸ’¬ **WeChat ç¾¤**: è§ README.md ä¸­çš„äºŒç»´ç 
ğŸ’¬ **è”ç³»é‚®ç®±**: yongjiang.jy@alibaba-inc.com

---

## é™„å½•

### A. é…ç½®å‚æ•°é€ŸæŸ¥è¡¨

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ | è°ƒä¼˜å»ºè®® |
|-----|--------|------|---------|
| `MAX_LLM_CALL_PER_RUN` | 100 | æœ€å¤§ LLM è°ƒç”¨æ¬¡æ•° | å¤æ‚ä»»åŠ¡å¢åŠ åˆ° 150 |
| `TIMEOUT` | 9000 ç§’ | å•æ¬¡æŸ¥è¯¢è¶…æ—¶ | ç®€å•ä»»åŠ¡å‡å°‘åˆ° 1800 |
| `MAX_CONTEXT_LENGTH` | 110000 tokens | æœ€å¤§ä¸Šä¸‹æ–‡ | ä¸å»ºè®®å¢åŠ  |
| `TEMPERATURE` | 0.85 | é‡‡æ ·æ¸©åº¦ | äº‹å®æŸ¥è¯¢é™ä½åˆ° 0.3 |
| `PRESENCE_PENALTY` | 1.1 | é‡å¤æƒ©ç½š | å¢åŠ åˆ° 1.5 æé«˜å¤šæ ·æ€§ |
| `MAX_WORKERS` | 20-30 | å¹¶å‘çº¿ç¨‹æ•° | æ ¹æ® GPU æ•°é‡è°ƒæ•´ |
| `ROLLOUT_COUNT` | 3 | Rollout æ¬¡æ•° | è¯„ä¼°æ—¶å¢åŠ åˆ° 5 |

### B. API æˆæœ¬ä¼°ç®—

| æœåŠ¡ | æ¯æ¬¡æˆæœ¬ | å…¸å‹ä½¿ç”¨é‡ | å•æŸ¥è¯¢æˆæœ¬ |
|-----|---------|-----------|-----------|
| Serper Search | $0.002 | 3-5 æ¬¡ | $0.006-0.01 |
| Jina Reader | $0.005 | 5-10 é¡µ | $0.025-0.05 |
| OpenAIæ‘˜è¦ (GPT-4) | $0.03/1K tokens | 50K tokens | $1.50 |
| Dashscope IDP | $0.05/æ–‡æ¡£ | 1-2 æ–‡æ¡£ | $0.05-0.10 |
| SandboxFusion | $0.001/æ‰§è¡Œ | 2-3 æ¬¡ | $0.002-0.003 |
| **æ€»è®¡** | - | - | **$1.58-1.66** |

**é™ä½æˆæœ¬çš„æ–¹æ³•**:
- ä½¿ç”¨ GPT-3.5 æ›¿ä»£ GPT-4 åšæ‘˜è¦ (æˆæœ¬é™ä½ 95%)
- å¯ç”¨ç¼“å­˜æœºåˆ¶
- é™åˆ¶ visit å·¥å…·çš„ä½¿ç”¨é¢‘ç‡

### C. æœ¯è¯­è¡¨

| æœ¯è¯­ | è‹±æ–‡ | è§£é‡Š |
|-----|------|------|
| **ReAct** | Reasoning + Acting | æ¨ç†ä¸è¡ŒåŠ¨äº¤æ›¿çš„ä»£ç†èŒƒå¼ |
| **Rollout** | - | ä¸€æ¬¡å®Œæ•´çš„æ¨ç†æ‰§è¡Œè¿‡ç¨‹ |
| **Tool Call** | - | ä»£ç†è°ƒç”¨å¤–éƒ¨å·¥å…·çš„è¡Œä¸º |
| **Context Length** | - | å¯¹è¯å†å²çš„ token æ€»æ•° |
| **Termination** | - | æ¨ç†ç»“æŸçš„åŸå›  |
| **DUPO** | Duplicating Sampling Policy Optimization | WebSailor çš„ RL ç®—æ³• |
| **MCP** | Model Context Protocol | æ¨¡å‹-æµè§ˆå™¨é€šä¿¡åè®® |
| **IDP** | Intelligent Document Processing | æ™ºèƒ½æ–‡æ¡£å¤„ç†æœåŠ¡ |
| **vLLM** | - | é«˜æ€§èƒ½ LLM æ¨ç†å¼•æ“ |
| **MoE** | Mixture of Experts | æ··åˆä¸“å®¶æ¨¡å‹æ¶æ„ |

---

*æœ¬æŒ‡å—æœ€åæ›´æ–°: 2026-01-19*
*ç‰ˆæœ¬: 1.0*
*ä½œè€…: Claude Code with Sonnet 4.5*
