# Tongyi DeepResearch é¡¹ç›®å®Œæ•´æŒ‡å—

> **ä¸€ä»½å¸®åŠ©æ‚¨å¿«é€Ÿç†è§£å’Œä½¿ç”¨ Tongyi DeepResearch çš„å®Œæ•´æŒ‡å—**

---

## ğŸ“š ç›®å½•

- [1. é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
- [2. æ ¸å¿ƒæ¦‚å¿µ](#2-æ ¸å¿ƒæ¦‚å¿µ)
- [3. å¿«é€Ÿå¼€å§‹](#3-å¿«é€Ÿå¼€å§‹)
- [4. ç³»ç»Ÿæ¶æ„æ·±åº¦è§£æ](#4-ç³»ç»Ÿæ¶æ„æ·±åº¦è§£æ)
- [5. ä½¿ç”¨æŒ‡å—](#5-ä½¿ç”¨æŒ‡å—)
- [6. é«˜çº§åŠŸèƒ½](#6-é«˜çº§åŠŸèƒ½)
- [7. å¼€å‘æŒ‡å—](#7-å¼€å‘æŒ‡å—)
- [8. å¸¸è§é—®é¢˜](#8-å¸¸è§é—®é¢˜)

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 Tongyi DeepResearch æ˜¯ä»€ä¹ˆï¼Ÿ

**Tongyi DeepResearchï¼ˆé€šä¹‰æ·±åº¦ç ”ç©¶ï¼‰** æ˜¯é˜¿é‡Œå·´å·´é€šä¹‰å®éªŒå®¤å¼€å‘çš„ä¸€ä¸ª**æ·±åº¦ä¿¡æ¯æœç´¢ä»£ç†ç³»ç»Ÿ**ï¼Œä¸“é—¨ç”¨äºè§£å†³éœ€è¦é•¿æ—¶é—´ã€å¤šæ­¥éª¤æ¨ç†çš„å¤æ‚ç ”ç©¶ä»»åŠ¡ã€‚

#### æ ¸å¿ƒç‰¹ç‚¹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Tongyi DeepResearch æ ¸å¿ƒèƒ½åŠ›                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  ğŸ§  30.5B å‚æ•° MoE æ¨¡å‹                                       â”‚
â”‚     â€¢ æ¯ä¸ª token åªæ¿€æ´» 3.3B å‚æ•°                            â”‚
â”‚     â€¢ 128K ä¸Šä¸‹æ–‡çª—å£                                         â”‚
â”‚     â€¢ é’ˆå¯¹ä»£ç†ä»»åŠ¡ä¼˜åŒ–çš„è®­ç»ƒæµç¨‹                              â”‚
â”‚                                                               â”‚
â”‚  ğŸ” å¤šæºä¿¡æ¯æ•´åˆ                                              â”‚
â”‚     â€¢ ç½‘ç»œæœç´¢ (Google Search)                                â”‚
â”‚     â€¢ å­¦æœ¯æœç´¢ (Google Scholar)                               â”‚
â”‚     â€¢ ç½‘é¡µæ·±åº¦é˜…è¯» + AI æ‘˜è¦                                  â”‚
â”‚     â€¢ æ–‡æ¡£è§£æ (PDF, Word, Excel, è§†é¢‘ç­‰ 15+ æ ¼å¼)           â”‚
â”‚     â€¢ Python ä»£ç æ‰§è¡Œ                                         â”‚
â”‚                                                               â”‚
â”‚  ğŸ¯ é•¿è§†é‡æ¨ç†                                                â”‚
â”‚     â€¢ æœ€å¤š 100 è½®äº¤äº’                                         â”‚
â”‚     â€¢ 150 åˆ†é’Ÿæ¨ç†æ—¶é—´                                        â”‚
â”‚     â€¢ è‡ªä¸»å·¥å…·è°ƒç”¨å†³ç­–                                        â”‚
â”‚                                                               â”‚
â”‚  ğŸ“Š SOTA æ€§èƒ½                                                 â”‚
â”‚     â€¢ Humanity's Last Exam: é¢†å…ˆæ€§èƒ½                          â”‚
â”‚     â€¢ BrowseComp: 12.0% (en), 30.1% (zh)                     â”‚
â”‚     â€¢ GAIA: 60.19%                                            â”‚
â”‚     â€¢ WebWalkerQA: 52.50%                                     â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 å®ƒèƒ½åšä»€ä¹ˆï¼Ÿ

#### å…¸å‹åº”ç”¨åœºæ™¯

| åœºæ™¯ | ç¤ºä¾‹ä»»åŠ¡ | éœ€è¦çš„èƒ½åŠ› |
|------|---------|-----------|
| ğŸ”¬ **å­¦æœ¯ç ”ç©¶** | "æ€»ç»“ 2024 å¹´é‡å­è®¡ç®—é¢†åŸŸçš„ä¸‰å¤§çªç ´" | å­¦æœ¯æœç´¢ + è®ºæ–‡é˜…è¯» + ä¿¡æ¯ç»¼åˆ |
| ğŸ’¼ **å¸‚åœºåˆ†æ** | "åˆ†æ Tesla åœ¨ä¸­å›½æ–°èƒ½æºè½¦å¸‚åœºçš„ç«äº‰æ€åŠ¿" | ç½‘ç»œæœç´¢ + æ•°æ®æå– + å¯¹æ¯”åˆ†æ |
| ğŸ“Š **æ•°æ®å¤„ç†** | "åˆ†æè¿™ä¸ª Excel è¡¨æ ¼å¹¶ç”Ÿæˆå¯è§†åŒ–" | æ–‡ä»¶è§£æ + Python æ‰§è¡Œ + æ•°æ®åˆ†æ |
| ğŸŒ **ä¿¡æ¯éªŒè¯** | "éªŒè¯æŸä¸ªæ–°é—»äº‹ä»¶çš„çœŸå®æ€§" | å¤šæºæœç´¢ + äº¤å‰éªŒè¯ + æ—¶é—´çº¿é‡å»º |
| ğŸ“– **æ·±åº¦é˜…è¯»** | "é˜…è¯»è¿™ä»½ 200 é¡µçš„æŠ€æœ¯æŠ¥å‘Šï¼Œæå–å…³é”®ä¿¡æ¯" | PDF è§£æ + å†…å®¹ç†è§£ + æ‘˜è¦ç”Ÿæˆ |
| ğŸ§® **å¤æ‚è®¡ç®—** | "è®¡ç®—æŸä¸ªæ•°å­¦/ç»Ÿè®¡é—®é¢˜" | Python æ‰§è¡Œ + æ•°å€¼è®¡ç®— + ç»“æœéªŒè¯ |

#### çœŸå®æ¡ˆä¾‹æ¼”ç¤º

**æ¡ˆä¾‹ 1: å¤šè·³æ¨ç†æŸ¥è¯¢**
```
ç”¨æˆ·: "æ‰¾å‡º 2024 å¹´è¯ºè´å°”ç‰©ç†å­¦å¥–å¾—ä¸»çš„æ¯æ ¡ï¼Œå¹¶åˆ—å‡ºè¯¥æ ¡è¿‘ 10 å¹´çš„è¯ºå¥–å¾—ä¸»æ•°é‡"

DeepResearch æ‰§è¡Œè¿‡ç¨‹:
1. ğŸ” æœç´¢ "2024 è¯ºè´å°”ç‰©ç†å­¦å¥–å¾—ä¸»"
2. ğŸ“„ è®¿é—®è¯ºè´å°”å®˜ç½‘è·å–è¯¦ç»†ä¿¡æ¯
3. ğŸ” æœç´¢å¾—ä¸»çš„æ•™è‚²èƒŒæ™¯
4. ğŸ“„ è®¿é—®å¤§å­¦å®˜ç½‘
5. ğŸ” æœç´¢è¯¥æ ¡å†å¹´è¯ºå¥–å¾—ä¸»
6. ğŸ“Š æ•´åˆä¿¡æ¯ï¼Œç”Ÿæˆç­”æ¡ˆ
```

**æ¡ˆä¾‹ 2: æ–‡æ¡£åˆ†æ + ç¼–ç¨‹**
```
ç”¨æˆ·: "åˆ†æè¿™ä¸ªé”€å”®æ•°æ® Excelï¼Œè®¡ç®—åŒæ¯”å¢é•¿ç‡å¹¶ç”»å›¾"

DeepResearch æ‰§è¡Œè¿‡ç¨‹:
1. ğŸ“ è§£æ Excel æ–‡ä»¶ï¼Œæå–æ•°æ®
2. ğŸ ç¼–å†™ Python ä»£ç è®¡ç®—å¢é•¿ç‡
3. ğŸ ä½¿ç”¨ matplotlib ç”Ÿæˆå¯è§†åŒ–
4. ğŸ“Š è¿”å›åˆ†æç»“æœå’Œå›¾è¡¨
```

### 1.3 ä¸å…¶ä»– AI ç³»ç»Ÿçš„åŒºåˆ«

| ç‰¹æ€§ | ä¼ ç»Ÿ LLM (GPT-4, Claude) | Tongyi DeepResearch |
|------|-------------------------|---------------------|
| **çŸ¥è¯†æ›´æ–°** | è®­ç»ƒæˆªæ­¢æ—¥æœŸå‰çš„çŸ¥è¯† | å®æ—¶ç½‘ç»œæœç´¢ |
| **ä¿¡æ¯æ¥æº** | å†…éƒ¨å‚æ•°è®°å¿† | å¤–éƒ¨å¤šæºéªŒè¯ |
| **æ¨ç†æ·±åº¦** | å•æ¬¡å¯¹è¯ | 100+ è½®è¿­ä»£æ¨ç† |
| **å·¥å…·ä½¿ç”¨** | æœ‰é™çš„å‡½æ•°è°ƒç”¨ | è‡ªä¸»çš„å¤šå·¥å…·ç¼–æ’ |
| **è¯æ®è¿½æº¯** | æ— æ³•æä¾›æ¥æº | å®Œæ•´çš„ä¿¡æ¯æ¥æºé“¾ |
| **å¤æ‚ä»»åŠ¡** | éœ€è¦äººå·¥æ‹†è§£ | è‡ªåŠ¨ä»»åŠ¡åˆ†è§£ |

### 1.4 é¡¹ç›®ç»„æˆ

```
DeepResearch ç”Ÿæ€ç³»ç»Ÿ
â”œâ”€ ğŸ“¦ æ ¸å¿ƒæ¨ç†å¼•æ“
â”‚  â”œâ”€ ReAct Agent (æ¨ç† + è¡ŒåŠ¨å¾ªç¯)
â”‚  â”œâ”€ 5 ä¸ªæ ¸å¿ƒå·¥å…· (æœç´¢ã€è®¿é—®ã€æ–‡ä»¶ã€ä»£ç ã€å­¦æœ¯)
â”‚  â””â”€ vLLM æ¨ç†æœåŠ¡å™¨
â”‚
â”œâ”€ ğŸŒ WebAgent å®¶æ— (13+ ä¸“ä¸šä»£ç†)
â”‚  â”œâ”€ WebDancer (åŸç”Ÿæœç´¢ä»£ç†)
â”‚  â”œâ”€ WebSailor (è¶…äººæ¨ç†)
â”‚  â”œâ”€ WebWatcher (è§†è§‰è¯­è¨€ä»£ç†)
â”‚  â”œâ”€ NestBrowse (æµè§ˆå™¨ä»£ç†)
â”‚  â””â”€ ... (æ›´å¤šä¸“ä¸šä»£ç†)
â”‚
â”œâ”€ ğŸ§ª è¯„ä¼°æ¡†æ¶
â”‚  â”œâ”€ å¤šåŸºå‡†æµ‹è¯•æ”¯æŒ
â”‚  â””â”€ LLM è¯„åˆ¤å™¨
â”‚
â””â”€ ğŸ› ï¸ è®­ç»ƒåŸºç¡€è®¾æ–½
   â”œâ”€ æ•°æ®åˆæˆç®¡é“
   â””â”€ å¼ºåŒ–å­¦ä¹ æ¡†æ¶
```

---

## 2. æ ¸å¿ƒæ¦‚å¿µ

### 2.1 ReAct èŒƒå¼

**ReAct = Reasoning (æ¨ç†) + Acting (è¡ŒåŠ¨)**

è¿™æ˜¯ä¸€ç§è®© AI æ¨¡å‹äº¤æ›¿è¿›è¡Œæ€è€ƒå’Œè¡ŒåŠ¨çš„æ¨ç†æ¨¡å¼ã€‚

```
ä¼ ç»Ÿ LLM:
ç”¨æˆ·æé—® â†’ æ¨¡å‹å›ç­” âœ“

ReAct Agent:
ç”¨æˆ·æé—®
  â†’ æ¨¡å‹æ€è€ƒï¼šæˆ‘éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯
  â†’ è¡ŒåŠ¨ï¼šè°ƒç”¨æœç´¢å·¥å…·
  â†’ è§‚å¯Ÿï¼šå¾—åˆ°æœç´¢ç»“æœ
  â†’ æ¨¡å‹æ€è€ƒï¼šæˆ‘éœ€è¦è®¿é—®æŸä¸ªç½‘é¡µ
  â†’ è¡ŒåŠ¨ï¼šè°ƒç”¨è®¿é—®å·¥å…·
  â†’ è§‚å¯Ÿï¼šå¾—åˆ°ç½‘é¡µå†…å®¹
  â†’ æ¨¡å‹æ€è€ƒï¼šç°åœ¨æˆ‘æœ‰è¶³å¤Ÿä¿¡æ¯äº†
  â†’ å›ç­”ï¼šç»™å‡ºæœ€ç»ˆç­”æ¡ˆ âœ“
```

#### ReAct å¾ªç¯å¯è§†åŒ–

```mermaid
graph LR
    A[ç”¨æˆ·æŸ¥è¯¢] --> B[æ€è€ƒ Think]
    B --> C{éœ€è¦æ›´å¤šä¿¡æ¯?}
    C -->|æ˜¯| D[è¡ŒåŠ¨ Act<br/>è°ƒç”¨å·¥å…·]
    D --> E[è§‚å¯Ÿ Observe<br/>å·¥å…·ç»“æœ]
    E --> B
    C -->|å¦| F[å›ç­” Answer]

    style A fill:#e1f5ff
    style F fill:#c8e6c9
    style D fill:#fff9c4
```

### 2.2 å·¥å…·ç³»ç»Ÿ (Tool System)

æ¯ä¸ªå·¥å…·éƒ½æ˜¯ä»£ç†ä¸å¤–éƒ¨ä¸–ç•Œäº¤äº’çš„æ¥å£ã€‚

#### å·¥å…·æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      å·¥å…·æ³¨å†Œè¡¨                          â”‚
â”‚             TOOL_MAP = {å·¥å…·å: å·¥å…·å®ä¾‹}                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
        â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¤–éƒ¨ API å·¥å…·   â”‚      â”‚  è®¡ç®—å‹å·¥å…·      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Search        â”‚      â”‚ â€¢ Python        â”‚
â”‚ â€¢ Visit         â”‚      â”‚   Interpreter   â”‚
â”‚ â€¢ Scholar       â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â€¢ FileParser    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è°ƒç”¨æµç¨‹:
<tool_call>                    å·¥å…·æ‰§è¡Œ
{"name": "search",    â†’    Serper API
 "arguments": {...}}        è¿”å›ç»“æœ
</tool_call>                   â†“
                     <tool_response>
                     æœç´¢ç»“æœ...
                     </tool_response>
```

#### 5 å¤§æ ¸å¿ƒå·¥å…·è¯¦è§£

**1. ğŸ” Search (ç½‘ç»œæœç´¢)**
```python
åŠŸèƒ½: Google æœç´¢
API: Serper.dev
è¾“å…¥: {"query": ["æŸ¥è¯¢1", "æŸ¥è¯¢2"]}
è¾“å‡º: Top 10 æœç´¢ç»“æœ (æ ‡é¢˜ã€URLã€æ‘˜è¦ã€æ—¥æœŸ)
ç‰¹æ€§:
  â€¢ æ‰¹é‡æŸ¥è¯¢æ”¯æŒ
  â€¢ ä¸­è‹±æ–‡è‡ªåŠ¨æ£€æµ‹
  â€¢ 5 æ¬¡é‡è¯•æœºåˆ¶
```

**2. ğŸ“„ Visit (ç½‘é¡µè®¿é—®)**
```python
åŠŸèƒ½: æ·±åº¦ç½‘é¡µé˜…è¯» + AI æ‘˜è¦
API: Jina AI (æŠ“å–) + OpenAI (æ‘˜è¦)
è¾“å…¥: {"url": ["ç½‘å€"], "goal": "ä¿¡æ¯ç›®æ ‡"}
è¾“å‡º: {rational, evidence, summary}
ç‰¹æ€§:
  â€¢ ä¸‰é˜¶æ®µå¤„ç†: æŠ“å– â†’ æˆªæ–­ â†’ æ‘˜è¦
  â€¢ æœ€å¤§å¤„ç† 95K tokens
  â€¢ ç»“æ„åŒ–ä¿¡æ¯æå–
```

**3. ğŸ“ FileParser (æ–‡ä»¶è§£æ)**
```python
åŠŸèƒ½: å¤šæ ¼å¼æ–‡ä»¶è§£æ
æ”¯æŒ: PDF, Word, Excel, PPT, è§†é¢‘, éŸ³é¢‘ç­‰ 15+ æ ¼å¼
API: Alibaba Dashscope IDP
è¾“å…¥: {"files": ["æ–‡ä»¶å1", "æ–‡ä»¶å2"]}
è¾“å‡º: Markdown æ ¼å¼çš„æ–‡ä»¶å†…å®¹
ç‰¹æ€§:
  â€¢ å¼‚æ­¥æ‰¹é‡å¤„ç†
  â€¢ è¡¨æ ¼ã€å›¾åƒæå–
  â€¢ OCR æ”¯æŒ
```

**4. ğŸ PythonInterpreter (ä»£ç æ‰§è¡Œ)**
```python
åŠŸèƒ½: å®‰å…¨çš„ Python ä»£ç æ‰§è¡Œ
API: SandboxFusion (å­—èŠ‚è·³åŠ¨)
è¾“å…¥: Python ä»£ç  (åœ¨ <code> æ ‡ç­¾ä¸­)
è¾“å‡º: stdout + stderr + æ‰§è¡Œæ—¶é—´
ç‰¹æ€§:
  â€¢ æ²™ç®±éš”ç¦»
  â€¢ 8 æ¬¡é‡è¯•
  â€¢ 50 ç§’è¶…æ—¶
  â€¢ å¤šç«¯ç‚¹è´Ÿè½½å‡è¡¡
```

**5. ğŸ“ Scholar (å­¦æœ¯æœç´¢)**
```python
åŠŸèƒ½: Google Scholar å­¦æœ¯æœç´¢
API: Serper Scholar
è¾“å…¥: {"query": ["å­¦æœ¯æŸ¥è¯¢"]}
è¾“å‡º: Top 10 è®ºæ–‡ (æ ‡é¢˜ã€ä½œè€…ã€å¼•ç”¨æ•°ã€PDF é“¾æ¥)
ç‰¹æ€§:
  â€¢ å¹¶å‘æŸ¥è¯¢ (3 çº¿ç¨‹)
  â€¢ å¼•ç”¨ä¿¡æ¯æå–
  â€¢ PDF ç›´é“¾
```

### 2.3 æç¤ºè¯å·¥ç¨‹ (Prompt Engineering)

ç³»ç»Ÿæç¤ºè¯å®šä¹‰äº†ä»£ç†çš„è¡Œä¸ºå’Œèƒ½åŠ›è¾¹ç•Œã€‚

**æ ¸å¿ƒæç¤ºè¯ç»“æ„**:

```xml
SYSTEM_PROMPT = """
[èº«ä»½å®šä¹‰]
You are a deep research assistant...

[å·¥å…·å®šä¹‰]
<tools>
{"type": "function", "function": {"name": "search", ...}}
{"type": "function", "function": {"name": "visit", ...}}
...
</tools>

[è°ƒç”¨æ ¼å¼]
<tool_call>
{"name": <function-name>, "arguments": <args-json-object>}
</tool_call>

[ç»ˆæ­¢æ ‡è®°]
<answer>æœ€ç»ˆç­”æ¡ˆ</answer>

[å½“å‰æ—¥æœŸ]
Current date: 2026-01-19
"""
```

**å…³é”®è®¾è®¡åŸåˆ™**:
1. âœ… **æ˜ç¡®çš„è§’è‰²å®šä¹‰**: "ä½ æ˜¯ä¸€ä¸ªæ·±åº¦ç ”ç©¶åŠ©æ‰‹"
2. âœ… **ç»“æ„åŒ–çš„å·¥å…·æè¿°**: JSON Schema æ ¼å¼
3. âœ… **æ¸…æ™°çš„è¾“å‡ºæ ¼å¼**: XML æ ‡ç­¾åŒ…è£¹
4. âœ… **ä¸Šä¸‹æ–‡ä¿¡æ¯**: å½“å‰æ—¥æœŸã€å¯ç”¨èµ„æº

### 2.4 è®­ç»ƒèŒƒå¼

Tongyi DeepResearch ä½¿ç”¨å››é˜¶æ®µè®­ç»ƒï¼š

```
é˜¶æ®µ 1: ğŸ—‚ï¸ æ•°æ®æ„å»º
â”œâ”€ åˆæˆé«˜è´¨é‡æœç´¢ä»»åŠ¡
â”œâ”€ æ”¶é›†ä¸“å®¶è½¨è¿¹
â””â”€ æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–

é˜¶æ®µ 2: ğŸ² è½¨è¿¹é‡‡æ ·
â”œâ”€ ä½¿ç”¨åŸºç¡€æ¨¡å‹ç”Ÿæˆå¤šæ ·åŒ–è½¨è¿¹
â”œâ”€ æ­£è´Ÿæ ·æœ¬æ ‡æ³¨
â””â”€ è½¨è¿¹è´¨é‡è¯„ä¼°

é˜¶æ®µ 3: ğŸ“š ç›‘ç£å¾®è°ƒ (SFT)
â”œâ”€ åœ¨ä¸“å®¶è½¨è¿¹ä¸Šè®­ç»ƒ
â”œâ”€ å­¦ä¹ å·¥å…·ä½¿ç”¨æ¨¡å¼
â””â”€ å†·å¯åŠ¨æ€§èƒ½æå‡

é˜¶æ®µ 4: ğŸ® å¼ºåŒ–å­¦ä¹  (RL)
â”œâ”€ å¥–åŠ±æ¨¡å‹è®­ç»ƒ
â”œâ”€ GRPO/DUPO ç­–ç•¥ä¼˜åŒ–
â””â”€ æ³›åŒ–èƒ½åŠ›æå‡
```

---

## 3. å¿«é€Ÿå¼€å§‹

### 3.1 ç¯å¢ƒå‡†å¤‡

#### ç³»ç»Ÿè¦æ±‚

```
ç¡¬ä»¶:
  â€¢ GPU: NVIDIA A100 (40GB+) æˆ– H100 æ¨è
  â€¢ æ˜¾å­˜: è‡³å°‘ 30GB (å•å¡)
  â€¢ CPU: 16+ æ ¸æ¨è
  â€¢ å†…å­˜: 64GB+ æ¨è

è½¯ä»¶:
  â€¢ Python: 3.10.0 (å¿…é¡»ï¼Œå…¶ä»–ç‰ˆæœ¬å¯èƒ½æœ‰ä¾èµ–é—®é¢˜)
  â€¢ CUDA: 12.0+
  â€¢ æ“ä½œç³»ç»Ÿ: Linux (æ¨è), macOS (æœ‰é™æ”¯æŒ)
```

#### æ­¥éª¤ 1: å…‹éš†ä»“åº“

```bash
git clone https://github.com/Alibaba-NLP/DeepResearch.git
cd DeepResearch
```

#### æ­¥éª¤ 2: åˆ›å»º Python ç¯å¢ƒ

```bash
# ä½¿ç”¨ Conda (æ¨è)
conda create -n react_infer_env python=3.10.0
conda activate react_infer_env

# æˆ–ä½¿ç”¨ virtualenv
python3.10 -m venv venv
source venv/bin/activate
```

#### æ­¥éª¤ 3: å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

**ä¾èµ–è¯´æ˜**:
- `vllm`: é«˜æ€§èƒ½ LLM æ¨ç†å¼•æ“
- `transformers`: Hugging Face æ¨¡å‹åº“
- `qwen-agent`: é€šä¹‰ä»£ç†æ¡†æ¶
- `openai`: OpenAI API å®¢æˆ·ç«¯
- `requests`: HTTP è¯·æ±‚åº“
- `asyncio`: å¼‚æ­¥ IO æ”¯æŒ

### 3.2 é…ç½® API å¯†é’¥

#### æ­¥éª¤ 1: å¤åˆ¶é…ç½®æ–‡ä»¶

```bash
cp .env.example .env
```

#### æ­¥éª¤ 2: ç¼–è¾‘ `.env` æ–‡ä»¶

```bash
# å¿…éœ€çš„ API å¯†é’¥
SERPER_KEY_ID=your_serper_key              # https://serper.dev/
JINA_API_KEYS=your_jina_key                # https://jina.ai/
API_KEY=your_openai_key                    # https://platform.openai.com/
API_BASE=https://api.openai.com/v1
DASHSCOPE_API_KEY=your_dashscope_key       # https://dashscope.aliyun.com/

# å¯é€‰: Python ä»£ç æ‰§è¡Œæ²™ç®±
SANDBOX_FUSION_ENDPOINT=http://localhost:8080

# æ¨¡å‹å’Œæ•°æ®è·¯å¾„
MODEL_PATH=/path/to/Tongyi-DeepResearch-30B-A3B
DATASET=eval_data/my_questions.jsonl
OUTPUT_PATH=./outputs
```

#### è·å– API å¯†é’¥æŒ‡å—

**Serper (æœç´¢ + å­¦æœ¯)**
1. è®¿é—® https://serper.dev/
2. æ³¨å†Œè´¦å·
3. è·å– API Key (å…è´¹é¢åº¦: 2,500 æ¬¡/æœˆ)

**Jina (ç½‘é¡µé˜…è¯»)**
1. è®¿é—® https://jina.ai/
2. æ³¨å†Œå¹¶è¿›å…¥ API Dashboard
3. åˆ›å»º API Key (å…è´¹é¢åº¦: 1,000 æ¬¡/å¤©)

**OpenAI (æ‘˜è¦ç”Ÿæˆ)**
1. è®¿é—® https://platform.openai.com/
2. è·å– API Key
3. æˆ–ä½¿ç”¨å…¼å®¹çš„ API (Azure OpenAI, é€šä¹‰åƒé—®ç­‰)

**Dashscope (æ–‡ä»¶è§£æ)**
1. è®¿é—® https://dashscope.aliyun.com/
2. é˜¿é‡Œäº‘è´¦å·ç™»å½•
3. å¼€é€šæœåŠ¡å¹¶è·å– API Key

**SandboxFusion (å¯é€‰, Python æ‰§è¡Œ)**
1. å‚è€ƒ https://github.com/bytedance/SandboxFusion
2. æœ¬åœ°éƒ¨ç½²æ²™ç®±æœåŠ¡
3. é…ç½®ç«¯ç‚¹ URL

### 3.3 ä¸‹è½½æ¨¡å‹

#### é€‰é¡¹ 1: ä» Hugging Face ä¸‹è½½

```bash
# ä½¿ç”¨ git-lfs
git lfs install
git clone https://huggingface.co/Alibaba-NLP/Tongyi-DeepResearch-30B-A3B

# æˆ–ä½¿ç”¨ huggingface-cli
pip install huggingface-hub
huggingface-cli download Alibaba-NLP/Tongyi-DeepResearch-30B-A3B \
    --local-dir ./models/deepresearch
```

#### é€‰é¡¹ 2: ä» ModelScope ä¸‹è½½

```bash
pip install modelscope
modelscope download --model iic/Tongyi-DeepResearch-30B-A3B \
    --local_dir ./models/deepresearch
```

#### é€‰é¡¹ 3: ä½¿ç”¨ OpenRouter API (æ— éœ€ä¸‹è½½)

ç¼–è¾‘ `inference/react_agent.py`:

```python
# ç¬¬ 61-62 è¡Œ
openai_api_key = "YOUR_OPENROUTER_KEY"
openai_api_base = "https://openrouter.ai/api/v1"

# ç¬¬ 76 è¡Œ
model = "alibaba/tongyi-deepresearch-30b-a3b"

# å–æ¶ˆæ³¨é‡Šç¬¬ 87-88 è¡Œ
reasoning_content = "<think>\n" + chat_response.choices[0].message.reasoning.strip() + "\n</think>"
content = reasoning_content + content
```

### 3.4 å‡†å¤‡æ•°æ®é›†

#### æ•°æ®æ ¼å¼

æ”¯æŒä¸¤ç§æ ¼å¼: **JSONL** (æ¨è) å’Œ **JSON**

**JSONL æ ¼å¼**:
```jsonl
{"question": "2024 å¹´è¯ºè´å°”ç‰©ç†å­¦å¥–å¾—ä¸»æ˜¯è°ï¼Ÿ", "answer": "çº¦ç¿°Â·éœæ™®è²å°”å¾·å’Œæ°å¼—é‡ŒÂ·è¾›é¡¿"}
{"question": "é‡å­è®¡ç®—çš„æœ€æ–°è¿›å±•æœ‰å“ªäº›ï¼Ÿ", "answer": "å‚è€ƒç­”æ¡ˆ..."}
{"question": "åˆ†æè¿™ä¸ª Excel è¡¨æ ¼çš„é”€å”®è¶‹åŠ¿", "answer": ""}
```

**JSON æ ¼å¼**:
```json
[
  {
    "question": "2024 å¹´è¯ºè´å°”ç‰©ç†å­¦å¥–å¾—ä¸»æ˜¯è°ï¼Ÿ",
    "answer": "çº¦ç¿°Â·éœæ™®è²å°”å¾·å’Œæ°å¼—é‡ŒÂ·è¾›é¡¿"
  },
  {
    "question": "é‡å­è®¡ç®—çš„æœ€æ–°è¿›å±•æœ‰å“ªäº›ï¼Ÿ",
    "answer": "å‚è€ƒç­”æ¡ˆ..."
  }
]
```

**å­—æ®µè¯´æ˜**:
- `question`: ç”¨æˆ·æŸ¥è¯¢ï¼ˆå¿…éœ€ï¼‰
- `answer`: å‚è€ƒç­”æ¡ˆï¼Œç”¨äºè¯„ä¼°ï¼ˆå¯é€‰ï¼Œç•™ç©ºè¡¨ç¤ºä»…ç”Ÿæˆç­”æ¡ˆï¼‰

#### æ–‡ä»¶å¼•ç”¨

å¦‚æœé—®é¢˜æ¶‰åŠæ–‡ä»¶ï¼Œéœ€è¦ï¼š

1. **åœ¨é—®é¢˜ä¸­å£°æ˜æ–‡ä»¶**:
```json
{
  "question": "(Uploaded 1 file: ['report.pdf'])\n\næ€»ç»“è¿™ä»½æŠ¥å‘Šçš„å…³é”®å‘ç°",
  "answer": "..."
}
```

2. **å°†æ–‡ä»¶æ”¾å…¥ `eval_data/file_corpus/` ç›®å½•**:
```bash
mkdir -p eval_data/file_corpus
cp /path/to/report.pdf eval_data/file_corpus/
```

#### ç¤ºä¾‹æ•°æ®é›†

åˆ›å»ºæµ‹è¯•æ–‡ä»¶ `eval_data/test_questions.jsonl`:

```jsonl
{"question": "ä»€ä¹ˆæ˜¯ Transformer æ¶æ„ï¼Ÿè¯·ç®€è¦è§£é‡Šå…¶å·¥ä½œåŸç†ã€‚", "answer": ""}
{"question": "æœç´¢å¹¶æ€»ç»“ GPT-4 å’Œ Claude 3 çš„ä¸»è¦åŒºåˆ«", "answer": ""}
{"question": "ç”¨ Python è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬ 20 é¡¹", "answer": "6765"}
```

### 3.5 è¿è¡Œç¬¬ä¸€æ¬¡æ¨ç†

#### æ–¹æ³• 1: ä½¿ç”¨å¯åŠ¨è„šæœ¬ (æ¨è)

```bash
# ç¼–è¾‘é…ç½®
vim .env

# ç¡®ä¿è®¾ç½®:
# MODEL_PATH=/path/to/model
# DATASET=eval_data/test_questions.jsonl
# OUTPUT_PATH=./outputs

# è¿è¡Œ
bash inference/run_react_infer.sh
```

**è„šæœ¬ä¼šè‡ªåŠ¨**:
1. å¯åŠ¨ 8 ä¸ª vLLM æœåŠ¡å™¨ (ç«¯å£ 6001-6008)
2. ç­‰å¾…æœåŠ¡å™¨å°±ç»ª
3. è¿è¡Œæ¨ç†ä»»åŠ¡
4. ä¿å­˜ç»“æœåˆ° `OUTPUT_PATH`

#### æ–¹æ³• 2: æ‰‹åŠ¨å¯åŠ¨

**æ­¥éª¤ 1: å¯åŠ¨ vLLM æœåŠ¡å™¨**

```bash
# ç»ˆç«¯ 1
CUDA_VISIBLE_DEVICES=0 vllm serve /path/to/model \
    --host 0.0.0.0 --port 6001 --disable-log-requests

# ç»ˆç«¯ 2 (å¦‚æœæœ‰å¤šä¸ª GPU)
CUDA_VISIBLE_DEVICES=1 vllm serve /path/to/model \
    --host 0.0.0.0 --port 6002 --disable-log-requests
```

**æ­¥éª¤ 2: è¿è¡Œæ¨ç†**

```bash
cd inference

python run_multi_react.py \
    --model /path/to/model \
    --dataset ../eval_data/test_questions.jsonl \
    --output ../outputs \
    --max_workers 2 \
    --roll_out_count 1 \
    --temperature 0.85 \
    --presence_penalty 1.1
```

#### æ–¹æ³• 3: ä½¿ç”¨ OpenRouter (æœ€ç®€å•)

å¦‚æœé…ç½®äº† OpenRouterï¼Œå¯ä»¥ç›´æ¥è¿è¡Œæ¨ç†è€Œæ— éœ€æœ¬åœ°éƒ¨ç½²æ¨¡å‹ï¼š

```bash
cd inference

python run_multi_react.py \
    --model "alibaba/tongyi-deepresearch-30b-a3b" \
    --dataset ../eval_data/test_questions.jsonl \
    --output ../outputs \
    --max_workers 5
```

### 3.6 æŸ¥çœ‹ç»“æœ

#### è¾“å‡ºç›®å½•ç»“æ„

```bash
outputs/
â”œâ”€â”€ test_questions_rollout_0.jsonl    # ç¬¬ 1 æ¬¡ rollout
â”œâ”€â”€ test_questions_rollout_1.jsonl    # ç¬¬ 2 æ¬¡ rollout
â”œâ”€â”€ test_questions_rollout_2.jsonl    # ç¬¬ 3 æ¬¡ rollout
â””â”€â”€ test_questions_summary.json       # æ±‡æ€»ç»Ÿè®¡
```

#### å•æ¡ç»“æœæ ¼å¼

```json
{
  "question": "ä»€ä¹ˆæ˜¯ Transformer æ¶æ„ï¼Ÿ",
  "answer": "",
  "prediction": "Transformer æ˜¯ä¸€ç§åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„...",
  "termination": "answer",
  "messages": [
    {"role": "system", "content": "You are a deep research assistant..."},
    {"role": "user", "content": "ä»€ä¹ˆæ˜¯ Transformer æ¶æ„ï¼Ÿ"},
    {"role": "assistant", "content": "<think>ç”¨æˆ·è¯¢é—® Transformer...</think>\n<tool_call>\n{\"name\": \"search\", \"arguments\": {\"query\": [\"Transformer æ¶æ„\"]}}\n</tool_call>"},
    {"role": "user", "content": "<tool_response>\næœç´¢ç»“æœ...\n</tool_response>"},
    {"role": "assistant", "content": "<answer>Transformer æ˜¯...</answer>"}
  ],
  "summary_record": "ç®€åŒ–çš„äº¤äº’è®°å½•"
}
```

**å­—æ®µè¯´æ˜**:
- `prediction`: æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆ
- `termination`: ç»ˆæ­¢åŸå› 
  - `answer`: æ­£å¸¸å®Œæˆ
  - `timeout`: è¶…æ—¶
  - `max_turn_exceeded`: è¾¾åˆ°æœ€å¤§è½®æ¬¡
  - `context_length_exceeded`: ä¸Šä¸‹æ–‡æº¢å‡º
- `messages`: å®Œæ•´çš„å¯¹è¯å†å²

#### æŸ¥çœ‹å®æ—¶æ—¥å¿—

```bash
# ç›‘æ§æ¨ç†è¿›åº¦
tail -f outputs/test_questions_rollout_0.jsonl

# æŸ¥çœ‹ vLLM æœåŠ¡å™¨æ—¥å¿—
# (åœ¨å¯åŠ¨ vLLM çš„ç»ˆç«¯æŸ¥çœ‹)
```

---

## 4. ç³»ç»Ÿæ¶æ„æ·±åº¦è§£æ

### 4.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ç”¨æˆ·å±‚ (User Layer)                           â”‚
â”‚  â€¢ ç ”ç©¶äººå‘˜è¾“å…¥å¤æ‚æŸ¥è¯¢                                                â”‚
â”‚  â€¢ è¯„ä¼°åŸºå‡†æ•°æ®é›† (GAIA, HLE, BrowseComp ç­‰)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®å¤„ç†å±‚ (Data Processing Layer)                 â”‚
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  run_multi_react.py (ç¼–æ’å™¨)                              â”‚        â”‚
â”‚  â”‚                                                            â”‚        â”‚
â”‚  â”‚  â€¢ åŠ è½½æ•°æ®é›† (JSONL/JSON)                                â”‚        â”‚
â”‚  â”‚  â€¢ ThreadPoolExecutor (é»˜è®¤ 20 çº¿ç¨‹)                      â”‚        â”‚
â”‚  â”‚  â€¢ ç«¯å£è½®è¯¢ (6001-6008)                                   â”‚        â”‚
â”‚  â”‚  â€¢ Rollout ç®¡ç† (æ¯ä¸ªé—®é¢˜ 3 æ¬¡)                           â”‚        â”‚
â”‚  â”‚  â€¢ æ£€æŸ¥ç‚¹æœºåˆ¶ (æ–­ç‚¹ç»­ä¼ )                                  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ä»£ç†å±‚ (Agent Layer)                               â”‚
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  MultiTurnReactAgent (ReAct æ ¸å¿ƒ)                         â”‚        â”‚
â”‚  â”‚                                                            â”‚        â”‚
â”‚  â”‚  ğŸ“ åˆå§‹åŒ–                                                 â”‚        â”‚
â”‚  â”‚     messages = [system_prompt, user_query]                â”‚        â”‚
â”‚  â”‚                                                            â”‚        â”‚
â”‚  â”‚  ğŸ”„ ä¸»å¾ªç¯ (æœ€å¤š 100 è½®)                                  â”‚        â”‚
â”‚  â”‚     for turn in range(100):                               â”‚        â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚        â”‚
â”‚  â”‚         â”‚ 1. LLM æ¨ç†                          â”‚           â”‚        â”‚
â”‚  â”‚         â”‚    response = call_server()          â”‚           â”‚        â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚        â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚        â”‚
â”‚  â”‚         â”‚ 2. è§£æå“åº”                          â”‚           â”‚        â”‚
â”‚  â”‚         â”‚    if <answer>: å®Œæˆ                â”‚           â”‚        â”‚
â”‚  â”‚         â”‚    if <tool_call>: æ‰§è¡Œå·¥å…·         â”‚           â”‚        â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚        â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚        â”‚
â”‚  â”‚         â”‚ 3. å·¥å…·è°ƒç”¨                          â”‚           â”‚        â”‚
â”‚  â”‚         â”‚    result = TOOL_MAP[tool_name]()   â”‚           â”‚        â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚        â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚        â”‚
â”‚  â”‚         â”‚ 4. æ›´æ–°ä¸Šä¸‹æ–‡                        â”‚           â”‚        â”‚
â”‚  â”‚         â”‚    messages.append(tool_response)   â”‚           â”‚        â”‚
â”‚  â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚        â”‚
â”‚  â”‚                                                            â”‚        â”‚
â”‚  â”‚  âš ï¸ ç»ˆæ­¢æ¡ä»¶æ£€æŸ¥                                          â”‚        â”‚
â”‚  â”‚     â€¢ ä¸Šä¸‹æ–‡é•¿åº¦ > 110K tokens                             â”‚        â”‚
â”‚  â”‚     â€¢ æ—¶é—´è¶…è¿‡ 150 åˆ†é’Ÿ                                    â”‚        â”‚
â”‚  â”‚     â€¢ è¾¾åˆ° 100 è½®                                          â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å·¥å…·å±‚ (Tool Layer)                                â”‚
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Search    â”‚  â”‚   Visit    â”‚  â”‚ FileParser â”‚  â”‚  Scholar   â”‚    â”‚
â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚  â”‚            â”‚    â”‚
â”‚  â”‚ Serper API â”‚  â”‚ Jina + LLM â”‚  â”‚ Dashscope  â”‚  â”‚ Serper API â”‚    â”‚
â”‚  â”‚            â”‚  â”‚            â”‚  â”‚ IDP        â”‚  â”‚            â”‚    â”‚
â”‚  â”‚ â€¢ æ‰¹é‡æŸ¥è¯¢ â”‚  â”‚ â€¢ 3 é˜¶æ®µ   â”‚  â”‚ â€¢ 15+ æ ¼å¼ â”‚  â”‚ â€¢ å¼•ç”¨è®¡æ•° â”‚    â”‚
â”‚  â”‚ â€¢ é‡è¯•     â”‚  â”‚ â€¢ 95K æˆªæ–­ â”‚  â”‚ â€¢ å¼‚æ­¥è§£æ â”‚  â”‚ â€¢ PDF é“¾æ¥ â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚       PythonInterpreter                 â”‚                          â”‚
â”‚  â”‚                                          â”‚                          â”‚
â”‚  â”‚ SandboxFusion (å­—èŠ‚è·³åŠ¨æ²™ç®±)             â”‚                          â”‚
â”‚  â”‚ â€¢ éš”ç¦»æ‰§è¡Œç¯å¢ƒ                           â”‚                          â”‚
â”‚  â”‚ â€¢ 8 æ¬¡é‡è¯•                               â”‚                          â”‚
â”‚  â”‚ â€¢ 50 ç§’è¶…æ—¶                              â”‚                          â”‚
â”‚  â”‚ â€¢ å¤šç«¯ç‚¹è´Ÿè½½å‡è¡¡                         â”‚                          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ¨¡å‹æ¨ç†å±‚ (Inference Layer)                       â”‚
â”‚                                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚         vLLM æœåŠ¡å™¨é›†ç¾¤ (Multi-GPU)                       â”‚        â”‚
â”‚  â”‚                                                            â”‚        â”‚
â”‚  â”‚  ç«¯å£ 6001 â—„â”€â”                        â”Œâ”€â–º ç«¯å£ 6005      â”‚        â”‚
â”‚  â”‚  ç«¯å£ 6002 â—„â”€â”¤                        â”œâ”€â–º ç«¯å£ 6006      â”‚        â”‚
â”‚  â”‚  ç«¯å£ 6003 â—„â”€â”¼â”€  è½®è¯¢è°ƒåº¦  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â–º ç«¯å£ 6007      â”‚        â”‚
â”‚  â”‚  ç«¯å£ 6004 â—„â”€â”˜                        â””â”€â–º ç«¯å£ 6008      â”‚        â”‚
â”‚  â”‚                                                            â”‚        â”‚
â”‚  â”‚  æ¨¡å‹: Tongyi-DeepResearch-30B-A3B                        â”‚        â”‚
â”‚  â”‚  â€¢ 30.5B æ€»å‚æ•°                                           â”‚        â”‚
â”‚  â”‚  â€¢ 3.3B æ¿€æ´»å‚æ•°/token                                    â”‚        â”‚
â”‚  â”‚  â€¢ 128K ä¸Šä¸‹æ–‡çª—å£                                        â”‚        â”‚
â”‚  â”‚  â€¢ temperature=0.85, presence_penalty=1.1                 â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    è¾“å‡ºå±‚ (Output Layer)                              â”‚
â”‚                                                                        â”‚
â”‚  â€¢ JSONL æ ¼å¼ç»“æœæ–‡ä»¶                                                 â”‚
â”‚  â€¢ å®Œæ•´å¯¹è¯å†å² (messages)                                            â”‚
â”‚  â€¢ ç»ˆæ­¢åŸå› æ ‡è®° (termination)                                         â”‚
â”‚  â€¢ å¯ä¾›è¯„ä¼°çš„é¢„æµ‹ç­”æ¡ˆ (prediction)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 ReAct æ‰§è¡Œæµç¨‹è¯¦è§£

#### æµç¨‹å›¾

```mermaid
stateDiagram-v2
    [*] --> Initialize
    Initialize: åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨
    Initialize: SYSTEM_PROMPT + ç”¨æˆ·æŸ¥è¯¢

    Initialize --> MainLoop

    MainLoop: ä¸»å¾ªç¯ (turn < 100)

    state MainLoop {
        [*] --> CallLLM
        CallLLM: è°ƒç”¨ vLLM API
        CallLLM: ç”Ÿæˆå“åº”

        CallLLM --> ParseResponse
        ParseResponse: è§£æ LLM è¾“å‡º

        ParseResponse --> CheckAnswer
        CheckAnswer: åŒ…å« <answer> æ ‡ç­¾?

        CheckAnswer --> ExtractAnswer: æ˜¯
        ExtractAnswer: æå–ç­”æ¡ˆ
        ExtractAnswer --> [*]

        CheckAnswer --> CheckToolCall: å¦
        CheckToolCall: åŒ…å« <tool_call>?

        CheckToolCall --> ParseToolCall: æ˜¯
        ParseToolCall: è§£æå·¥å…·åç§°å’Œå‚æ•°

        ParseToolCall --> RouteToTool
        RouteToTool: ä» TOOL_MAP è·å–å·¥å…·

        RouteToTool --> ExecuteTool
        ExecuteTool: è°ƒç”¨ tool.call()

        ExecuteTool --> WrapResponse
        WrapResponse: åŒ…è£…ä¸º <tool_response>

        WrapResponse --> AppendToMessages
        AppendToMessages: è¿½åŠ åˆ°æ¶ˆæ¯å†å²

        AppendToMessages --> CheckContext
        CheckContext: ä¸Šä¸‹æ–‡ < 110K?

        CheckContext --> CallLLM: æ˜¯
        CheckContext --> [*]: å¦ (æº¢å‡º)

        CheckToolCall --> DirectResponse: å¦
        DirectResponse: ç›´æ¥å“åº”æ–‡æœ¬
        DirectResponse --> CallLLM
    }

    MainLoop --> Success: å‘ç°ç­”æ¡ˆ
    MainLoop --> ContextOverflow: ä¸Šä¸‹æ–‡æº¢å‡º
    MainLoop --> MaxTurn: è¾¾åˆ° 100 è½®
    MainLoop --> Timeout: è¶…è¿‡ 150 åˆ†é’Ÿ

    Success --> [*]
    ContextOverflow --> [*]
    MaxTurn --> [*]
    Timeout --> [*]
```

#### ä»£ç è·¯å¾„è¿½è¸ª

**å…¥å£**: `inference/run_multi_react.py:main()`

```python
# ç¬¬ 55 è¡Œ: åŠ è½½æ•°æ®é›†
dataset = load_jsonl_or_json(args.dataset)

# ç¬¬ 62 è¡Œ: åˆ›å»ºçº¿ç¨‹æ± 
with ThreadPoolExecutor(max_workers=args.max_workers) as executor:
    # ç¬¬ 70 è¡Œ: æäº¤ä»»åŠ¡
    futures = []
    for idx, sample in enumerate(dataset):
        for rollout in range(args.roll_out_count):
            port = ports[idx % len(ports)]
            future = executor.submit(
                process_sample,  # â† å…³é”®å‡½æ•°
                sample,
                args.model,
                port,
                rollout
            )
            futures.append(future)
```

**æ ¸å¿ƒå‡½æ•°**: `process_sample()` â†’ `MultiTurnReactAgent._run()`

```python
# inference/react_agent.py:126-226

def _run(self, data, model, planning_port):
    # ç¬¬ 134 è¡Œ: åˆå§‹åŒ–æ¶ˆæ¯
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT + today_date()},
        {"role": "user", "content": data['question']}
    ]

    # ç¬¬ 141 è¡Œ: ä¸»å¾ªç¯
    for turn in range(MAX_LLM_CALL_PER_RUN):  # 100 è½®
        # ç¬¬ 145 è¡Œ: è°ƒç”¨ LLM
        response = self.call_server(messages, planning_port)
        messages.append({"role": "assistant", "content": response})

        # ç¬¬ 155 è¡Œ: æ£€æŸ¥ç­”æ¡ˆ
        if "<answer>" in response and "</answer>" in response:
            prediction = extract_between_tags(response, "answer")
            return messages, prediction, "answer"

        # ç¬¬ 165 è¡Œ: æ£€æŸ¥å·¥å…·è°ƒç”¨
        if "<tool_call>" in response:
            tool_calls = extract_tool_calls(response)

            for tool_call in tool_calls:
                # ç¬¬ 170 è¡Œ: è§£æå·¥å…·
                func_name = tool_call["name"]
                func_args = tool_call["arguments"]

                # ç¬¬ 180 è¡Œ: æ‰§è¡Œå·¥å…·
                tool_result = self.custom_call_tool(func_name, func_args)

                # ç¬¬ 185 è¡Œ: åŒ…è£…å“åº”
                obs = f"<tool_response>\n{tool_result}\n</tool_response>"
                messages.append({"role": "user", "content": obs})

        # ç¬¬ 195 è¡Œ: æ£€æŸ¥ä¸Šä¸‹æ–‡é•¿åº¦
        if get_token_count(messages) > 110000:
            return messages, None, "context_length_exceeded"

        # ç¬¬ 205 è¡Œ: æ£€æŸ¥è¶…æ—¶
        if time.time() - start_time > 9000:  # 150 åˆ†é’Ÿ
            return messages, None, "timeout"

    # ç¬¬ 220 è¡Œ: è¾¾åˆ°æœ€å¤§è½®æ¬¡
    return messages, None, "max_turn_exceeded"
```

### 4.3 å·¥å…·æ‰§è¡Œæ·±åº¦åˆ†æ

#### ä»¥ Visit å·¥å…·ä¸ºä¾‹

**å®Œæ•´è°ƒç”¨é“¾**:

```
ç”¨æˆ·æŸ¥è¯¢
  â””â”€> ReAct Agent å†³ç­–éœ€è¦è®¿é—®ç½‘é¡µ
      â””â”€> ç”Ÿæˆ <tool_call>{"name": "visit", "arguments": {...}}</tool_call>
          â””â”€> custom_call_tool() è§£æå¹¶è·¯ç”±
              â””â”€> TOOL_MAP["visit"].call(params)
                  â”‚
                  â””â”€> tool_visit.py:Visit.call()
                      â”‚
                      â”œâ”€ æ­¥éª¤ 1: è§£æå‚æ•°
                      â”‚  url_list = params["url"]
                      â”‚  goal = params["goal"]
                      â”‚
                      â”œâ”€ æ­¥éª¤ 2: æŠ“å–ç½‘é¡µ (readpage_jina)
                      â”‚  â””â”€> requests.get(f"https://r.jina.ai/{url}")
                      â”‚      â€¢ è®¤è¯: Bearer {JINA_API_KEY}
                      â”‚      â€¢ è¶…æ—¶: 200 ç§’
                      â”‚      â€¢ é‡è¯•: 3 æ¬¡
                      â”‚      â€¢ è¿”å›: Markdown æ ¼å¼çš„ç½‘é¡µå†…å®¹
                      â”‚
                      â”œâ”€ æ­¥éª¤ 3: Token æˆªæ–­
                      â”‚  if len(tokens) > 95000:
                      â”‚      content = truncate(content, 95000)
                      â”‚
                      â”œâ”€ æ­¥éª¤ 4: LLM æ‘˜è¦ (extract_relevant_info)
                      â”‚  â””â”€> OpenAI API è°ƒç”¨
                      â”‚      â€¢ Prompt: EXTRACTOR_PROMPT
                      â”‚      â€¢ è¾“å…¥: {webpage_content, goal}
                      â”‚      â€¢ è¾“å‡º: JSON {rational, evidence, summary}
                      â”‚      â€¢ é‡è¯•: 3 æ¬¡
                      â”‚
                      â””â”€ æ­¥éª¤ 5: æ ¼å¼åŒ–è¿”å›
                         return f"""
                         # URL: {url}

                         **ç†ç”±**: {rational}
                         **è¯æ®**: {evidence}
                         **æ€»ç»“**: {summary}
                         """
```

**æ€§èƒ½ç‰¹æ€§**:

| é˜¶æ®µ | è€—æ—¶ (ä¼°ç®—) | ç“¶é¢ˆ | ä¼˜åŒ–æ–¹å‘ |
|-----|------------|------|---------|
| Jina æŠ“å– | 2-10 ç§’ | ç½‘ç»œ I/O | å¹¶å‘æŠ“å–ã€ç¼“å­˜ |
| Token æˆªæ–­ | <1 ç§’ | è®¡ç®— | å·²ä¼˜åŒ– |
| LLM æ‘˜è¦ | 5-20 ç§’ | API è°ƒç”¨ | æ‰¹é‡å¤„ç†ã€æ›´å¿«æ¨¡å‹ |
| æ€»è®¡ | 7-31 ç§’/é¡µ | - | å¼‚æ­¥åŒ–ã€ç¼“å­˜ |

#### å·¥å…·å¹¶å‘æ¨¡å¼å¯¹æ¯”

**å½“å‰æ¨¡å¼: ä¸²è¡Œæ‰§è¡Œ**
```python
for tool_call in tool_calls:
    result = execute_tool(tool_call)
    # ç­‰å¾…å®Œæˆåå†æ‰§è¡Œä¸‹ä¸€ä¸ª
```

**ä¼˜åŒ–å: å¹¶è¡Œæ‰§è¡Œ** (æ‰©å±•ç‚¹)
```python
# åˆ†ç»„ç›¸åŒç±»å‹çš„å·¥å…·
grouped = group_by_tool_type(tool_calls)

# æ‰¹é‡æ‰§è¡Œ
results = {}
for tool_type, calls in grouped.items():
    if tool_type in ["search", "visit", "scholar"]:
        # å¯ä»¥å¹¶è¡Œ
        results[tool_type] = asyncio.gather(*[
            execute_async(call) for call in calls
        ])
    else:
        # ä¸²è¡Œ
        results[tool_type] = [execute(call) for call in calls]
```

### 4.4 WebAgent å®¶æ—æ¶æ„

DeepResearch åŒ…å«ä¸€ä¸ªåºå¤§çš„ WebAgent å®¶æ—ï¼Œæ¯ä¸ªæˆå‘˜éƒ½æœ‰ä¸“é—¨çš„èƒ½åŠ›ã€‚

#### å®¶æ—å…³ç³»å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Tongyi DeepResearch (æ ¸å¿ƒ)                   â”‚
â”‚         ä¸»æ¨ç†å¼•æ“ + 5 å¤§å·¥å…· + ReAct èŒƒå¼                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                             â”‚
        â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  åŸºç¡€ä»£ç†å®¶æ—      â”‚         â”‚  ä¸“ä¸šä»£ç†å®¶æ—      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ WebWalker       â”‚         â”‚ â€¢ WebWatcher      â”‚
â”‚   åŸºå‡†æµ‹è¯•        â”‚         â”‚   è§†è§‰è¯­è¨€        â”‚
â”‚                   â”‚         â”‚                   â”‚
â”‚ â€¢ WebDancer       â”‚         â”‚ â€¢ WebShaper       â”‚
â”‚   åŸç”Ÿæœç´¢        â”‚         â”‚   æ•°æ®åˆæˆ        â”‚
â”‚                   â”‚         â”‚                   â”‚
â”‚ â€¢ WebSailor       â”‚         â”‚ â€¢ WebWeaver       â”‚
â”‚   è¶…äººæ¨ç†        â”‚         â”‚   è¯æ®ç»“æ„åŒ–      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                             â”‚
        â–¼                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç³»ç»Ÿå¢å¼ºå®¶æ—      â”‚         â”‚  æ¨ç†å¢å¼ºå®¶æ—      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ NestBrowse      â”‚         â”‚ â€¢ ParallelMuse    â”‚
â”‚   æµè§ˆå™¨äº¤äº’      â”‚         â”‚   å¹¶è¡Œè½¨è¿¹        â”‚
â”‚                   â”‚         â”‚                   â”‚
â”‚ â€¢ WebResummer     â”‚         â”‚ â€¢ WebResearcher   â”‚
â”‚   ä¸Šä¸‹æ–‡æ‘˜è¦      â”‚         â”‚   é•¿è§†é‡æ¨ç†      â”‚
â”‚                   â”‚         â”‚                   â”‚
â”‚ â€¢ WebLeaper       â”‚         â”‚ â€¢ AgentScaler     â”‚
â”‚   ä¿¡æ¯è·³è·ƒ        â”‚         â”‚   æŒç»­é¢„è®­ç»ƒ      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ä»£è¡¨æ€§é¡¹ç›®æ·±åº¦è§£æ

**1. NestBrowse - æµè§ˆå™¨ä»£ç†**

```
ç‰¹ç‚¹: ä½¿ç”¨ MCP (Model Context Protocol) ä¸æµè§ˆå™¨äº¤äº’

æ¶æ„:
WebAgent/NestBrowse/
â”œâ”€ infer_async_nestbrowse.py    # å¼‚æ­¥ä¸»å¾ªç¯
â”œâ”€ toolkit/
â”‚  â”œâ”€ browser.py                # æµè§ˆå™¨å·¥å…·
â”‚  â”‚  â”œâ”€ Visit(url)             # å¯¼èˆªåˆ° URL
â”‚  â”‚  â”œâ”€ Click(element_id)      # ç‚¹å‡»å…ƒç´ 
â”‚  â”‚  â””â”€ Fill(element_id, text) # å¡«å……è¡¨å•
â”‚  â”œâ”€ mcp_client.py             # MCP åè®®å®¢æˆ·ç«¯
â”‚  â””â”€ tool_search.py            # æœç´¢å·¥å…·
â””â”€ prompts.py                   # æç¤ºè¯

æ‰§è¡Œæ¨¡å¼:
async def agentic_loop():
    for turn in range(MAX_AGENT_TURN):
        # å¼‚æ­¥è°ƒç”¨ LLM
        async with sem['llm']:
            response = await call_llm()

        # è§£æå·¥å…·è°ƒç”¨
        if "<tool_call>" in response:
            # å¼‚æ­¥æ‰§è¡Œå·¥å…·
            async with sem['tool']:
                result = await call_tool()

        # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
        if "<answer>" in response:
            break

æ€§èƒ½ä¼˜åŠ¿:
â€¢ å¼‚æ­¥ I/O: å¤šä¸ªç½‘é¡µå¯å¹¶å‘å¤„ç†
â€¢ ä¿¡å·é‡é™æµ: æ§åˆ¶å¹¶å‘æ•°ï¼Œé¿å…è¿‡è½½
â€¢ æµè§ˆå™¨çŠ¶æ€: æ”¯æŒå¤šæ­¥äº¤äº’ (ç‚¹å‡»ã€å¡«è¡¨ã€ç¿»é¡µ)
```

**2. ParallelMuse - å¹¶è¡Œè½¨è¿¹èšåˆ**

```
ç‰¹ç‚¹: è¿è¡Œå¤šä¸ªç‹¬ç«‹è½¨è¿¹ï¼Œç„¶åèšåˆç»“æœ

æ¶æ„:
WebAgent/ParallelMuse/
â”œâ”€ compressed_reasoning_aggregation.py
â”‚  â”œâ”€ call_state_report()      # è½¨è¿¹ â†’ æŠ¥å‘Š
â”‚  â””â”€ call_info_integrate()    # æŠ¥å‘Š â†’ æœ€ç»ˆç­”æ¡ˆ
â””â”€ prompts.py
   â”œâ”€ REPORT_PROMPT             # æå–æ¨ç†è¿‡ç¨‹
   â””â”€ INTEGRATE_PROMPT          # èšåˆå¤šä¸ªæŠ¥å‘Š

å·¥ä½œæµç¨‹:
1. ç”Ÿæˆ N ä¸ªç‹¬ç«‹è½¨è¿¹ (rollouts)
   rollouts = [run_agent(question) for _ in range(N)]

2. ä¸ºæ¯ä¸ªè½¨è¿¹ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š
   reports = []
   for rollout in rollouts:
       report = LLM(REPORT_PROMPT + rollout.messages)
       # è¾“å‡º: {solution_planning, methods, final_reasoning}
       reports.append(report)

3. èšåˆæ‰€æœ‰æŠ¥å‘Š
   final_answer = LLM(INTEGRATE_PROMPT + reports)
   # åˆ†æä¸€è‡´æ€§ã€é€‰æ‹©æœ€ä½³ç­”æ¡ˆ

ä¼˜åŠ¿:
â€¢ å¤šæ ·æ€§: ä¸åŒè½¨è¿¹æ¢ç´¢ä¸åŒè·¯å¾„
â€¢ é²æ£’æ€§: å•ä¸ªè½¨è¿¹å¤±è´¥ä¸å½±å“æ•´ä½“
â€¢ è´¨é‡: èšåˆå¯ä»¥è¿‡æ»¤é”™è¯¯ç­”æ¡ˆ
```

**3. WebSailor - è¶…äººæ¨ç†**

```
ç‰¹ç‚¹: 2 é˜¶æ®µè®­ç»ƒ + DUPO å¼ºåŒ–å­¦ä¹ 

è®­ç»ƒæµç¨‹:
é˜¶æ®µ 1: RFT (Rejection Fine-Tuning) å†·å¯åŠ¨
â€¢ æ”¶é›†ä¸“å®¶è½¨è¿¹ + æ¨¡å‹è½¨è¿¹
â€¢ äººå·¥æ ‡æ³¨æ­£è´Ÿæ ·æœ¬
â€¢ ä»…åœ¨æ­£æ ·æœ¬ä¸Šå¾®è°ƒ

é˜¶æ®µ 2: DUPO (Duplicating Sampling Policy Optimization)
â€¢ æ¯ä¸ªæŸ¥è¯¢é‡‡æ ·å¤šä¸ªè½¨è¿¹
â€¢ è®¡ç®—å¥–åŠ±: R = f(answer, ground_truth)
â€¢ ç­–ç•¥æ¢¯åº¦æ›´æ–°: âˆ‡Î¸ = E[R * âˆ‡log Ï€(a|s)]

æ•°æ®é›†: SailorFog-QA
â€¢ é«˜ä¸ç¡®å®šæ€§ã€é«˜éš¾åº¦ QA æ•°æ®
â€¢ å›¾é‡‡æ · + ä¿¡æ¯æ··æ·†ç”Ÿæˆ
â€¢ éœ€è¦å¤šè·³æ¨ç†å’Œæ·±åº¦æœç´¢

æ€§èƒ½:
â€¢ BrowseComp-en: 12.0%
â€¢ BrowseComp-zh: 30.1%
â€¢ GAIA: 55.4%
```

---

## 5. ä½¿ç”¨æŒ‡å—

### 5.1 åŸºç¡€ä½¿ç”¨

#### åœºæ™¯ 1: ç®€å•äº‹å®æŸ¥è¯¢

```bash
# åˆ›å»ºæŸ¥è¯¢æ–‡ä»¶
cat > eval_data/simple_query.jsonl << EOF
{"question": "2024 å¹´å›¾çµå¥–å¾—ä¸»æ˜¯è°ï¼Ÿ", "answer": ""}
EOF

# è¿è¡Œæ¨ç†
python inference/run_multi_react.py \
    --model $MODEL_PATH \
    --dataset eval_data/simple_query.jsonl \
    --output outputs \
    --max_workers 1 \
    --roll_out_count 1

# æŸ¥çœ‹ç»“æœ
cat outputs/simple_query_rollout_0.jsonl | jq '.prediction'
```

**é¢„æœŸæ‰§è¡Œæµç¨‹**:
```
1. [Search] "2024 å›¾çµå¥–å¾—ä¸»"
2. [Visit] ACM å®˜ç½‘é¡µé¢
3. [Answer] ç­”æ¡ˆ: XXX
```

#### åœºæ™¯ 2: å­¦æœ¯æ–‡çŒ®è°ƒç ”

```bash
# æŸ¥è¯¢
cat > eval_data/academic_query.jsonl << EOF
{"question": "æ€»ç»“ 2024 å¹´ NeurIPS å…³äº Transformer ä¼˜åŒ–çš„ä¸»è¦è®ºæ–‡", "answer": ""}
EOF

# è¿è¡Œ
python inference/run_multi_react.py \
    --model $MODEL_PATH \
    --dataset eval_data/academic_query.jsonl \
    --output outputs \
    --max_workers 1
```

**é¢„æœŸæ‰§è¡Œæµç¨‹**:
```
1. [Scholar] "NeurIPS 2024 Transformer optimization"
2. [Visit] è®ºæ–‡ 1 é¡µé¢ï¼Œæå–æ‘˜è¦
3. [Visit] è®ºæ–‡ 2 é¡µé¢ï¼Œæå–æ‘˜è¦
4. [Visit] è®ºæ–‡ 3 é¡µé¢ï¼Œæå–æ‘˜è¦
5. [Search] "NeurIPS 2024 best papers"
6. [Answer] ç»¼åˆæ€»ç»“
```

#### åœºæ™¯ 3: æ–‡æ¡£åˆ†æ

```bash
# å‡†å¤‡æ–‡ä»¶
cp /path/to/report.pdf eval_data/file_corpus/

# æŸ¥è¯¢
cat > eval_data/doc_query.jsonl << EOF
{"question": "(Uploaded 1 file: ['report.pdf'])\n\næ€»ç»“è¿™ä»½æŠ¥å‘Šçš„æ ¸å¿ƒè§‚ç‚¹å’Œæ•°æ®æ”¯æ’‘", "answer": ""}
EOF

# è¿è¡Œ
python inference/run_multi_react.py \
    --model $MODEL_PATH \
    --dataset eval_data/doc_query.jsonl \
    --output outputs
```

**é¢„æœŸæ‰§è¡Œæµç¨‹**:
```
1. [FileParser] è§£æ report.pdf
2. [PythonInterpreter] (å¯é€‰) å¦‚æœéœ€è¦æ•°æ®åˆ†æ
3. [Answer] æ€»ç»“æ ¸å¿ƒè§‚ç‚¹
```

#### åœºæ™¯ 4: æ•°æ®åˆ†æ + å¯è§†åŒ–

```bash
# æŸ¥è¯¢
cat > eval_data/data_query.jsonl << EOF
{"question": "ç”Ÿæˆ 1-100 çš„éšæœºæ•°åˆ—è¡¨ï¼Œè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®ï¼Œå¹¶ç”»ç›´æ–¹å›¾", "answer": ""}
EOF

# è¿è¡Œ
python inference/run_multi_react.py \
    --model $MODEL_PATH \
    --dataset eval_data/data_query.jsonl \
    --output outputs
```

**é¢„æœŸæ‰§è¡Œæµç¨‹**:
```
1. [PythonInterpreter]
   import numpy as np
   import matplotlib.pyplot as plt

   data = np.random.randint(1, 101, 100)
   mean = np.mean(data)
   std = np.std(data)

   plt.hist(data, bins=20)
   plt.savefig('histogram.png')

   print(f"å‡å€¼: {mean}, æ ‡å‡†å·®: {std}")

2. [Answer] è¿”å›ç»Ÿè®¡ç»“æœ
```

### 5.2 é«˜çº§å‚æ•°è°ƒä¼˜

#### æ¸©åº¦ (Temperature)

æ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§ã€‚

```bash
# ä½æ¸©åº¦ (æ›´ç¡®å®šæ€§ã€æ›´ä¿å®ˆ)
python run_multi_react.py \
    --temperature 0.3 \
    ...

# ä¸­æ¸©åº¦ (å¹³è¡¡ï¼Œé»˜è®¤)
--temperature 0.85

# é«˜æ¸©åº¦ (æ›´å¤šæ ·æ€§ã€æ›´åˆ›é€ æ€§)
--temperature 1.2
```

**ä½¿ç”¨å»ºè®®**:
- äº‹å®æŸ¥è¯¢: 0.3-0.5
- å¼€æ”¾å¼ç ”ç©¶: 0.7-0.9
- åˆ›æ„ç”Ÿæˆ: 1.0-1.5

#### Presence Penalty

æƒ©ç½šå·²å‡ºç°çš„ tokenï¼Œé¼“åŠ±æ–°å†…å®¹ã€‚

```bash
# ä½æƒ©ç½š (å¯èƒ½é‡å¤)
--presence_penalty 0.5

# ä¸­æƒ©ç½š (é»˜è®¤)
--presence_penalty 1.1

# é«˜æƒ©ç½š (å¼ºåˆ¶å¤šæ ·æ€§)
--presence_penalty 1.5
```

#### Rollout æ¬¡æ•°

æ¯ä¸ªé—®é¢˜è¿è¡Œå¤šæ¬¡ï¼Œå¢åŠ é²æ£’æ€§ã€‚

```bash
# å•æ¬¡è¿è¡Œ (å¿«é€Ÿæµ‹è¯•)
--roll_out_count 1

# 3 æ¬¡è¿è¡Œ (é»˜è®¤ï¼Œå¹³è¡¡)
--roll_out_count 3

# 5 æ¬¡è¿è¡Œ (é«˜è´¨é‡ï¼Œç”¨äºè¯„ä¼°)
--roll_out_count 5
```

**å¤š Rollout çš„å¥½å¤„**:
- è¦†ç›–ä¸åŒæ¨ç†è·¯å¾„
- å¯ä»¥é€‰æ‹©æœ€ä½³ç­”æ¡ˆ (majority voting)
- å¢åŠ æˆåŠŸç‡

#### å¹¶å‘å·¥ä½œçº¿ç¨‹

```bash
# ä½å¹¶å‘ (èµ„æºå—é™)
--max_workers 5

# ä¸­å¹¶å‘ (é»˜è®¤)
--max_workers 20

# é«˜å¹¶å‘ (å¤š GPU)
--max_workers 50
```

**æ³¨æ„äº‹é¡¹**:
- ç¡®ä¿ `max_workers` â‰¤ vLLM æœåŠ¡å™¨æ•°é‡ Ã— æ¯æœåŠ¡å™¨å¹¶å‘èƒ½åŠ›
- è¿‡é«˜çš„å¹¶å‘å¯èƒ½å¯¼è‡´ API é™æµæˆ– OOM

### 5.3 åˆ†å¸ƒå¼æ¨ç†

#### å•æœºå¤š GPU

é»˜è®¤é…ç½®å·²æ”¯æŒï¼Œæ— éœ€é¢å¤–è®¾ç½®ã€‚

```bash
# run_react_infer.sh ä¼šè‡ªåŠ¨å¯åŠ¨ 8 ä¸ª vLLM æœåŠ¡å™¨
bash inference/run_react_infer.sh
```

#### å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼

**é…ç½®ç¯å¢ƒå˜é‡**:

```bash
# èŠ‚ç‚¹ 1
export WORLD_SIZE=2
export RANK=0
bash inference/run_react_infer.sh

# èŠ‚ç‚¹ 2
export WORLD_SIZE=2
export RANK=1
bash inference/run_react_infer.sh
```

**æ•°æ®åˆ†ç‰‡é€»è¾‘** (`run_multi_react.py`):

```python
# ç¬¬ 30-45 è¡Œ
if args.total_splits > 1:
    # åˆ†ç‰‡ç´¢å¼•: [start, end)
    shard_size = len(dataset) // args.total_splits
    start_idx = (args.worker_split - 1) * shard_size
    end_idx = args.worker_split * shard_size if args.worker_split < args.total_splits else len(dataset)
    dataset = dataset[start_idx:end_idx]
```

#### æ–­ç‚¹ç»­ä¼ 

ç³»ç»Ÿè‡ªåŠ¨æ”¯æŒæ£€æŸ¥ç‚¹æœºåˆ¶ã€‚

```bash
# å¦‚æœæ¨ç†ä¸­æ–­ï¼Œé‡æ–°è¿è¡Œç›¸åŒå‘½ä»¤
python run_multi_react.py \
    --model $MODEL_PATH \
    --dataset eval_data/questions.jsonl \
    --output outputs \
    ...

# ç³»ç»Ÿä¼š:
# 1. æ‰«æ outputs/ ç›®å½•
# 2. è¯†åˆ«å·²å®Œæˆçš„æ ·æœ¬
# 3. è·³è¿‡å·²å®Œæˆï¼Œç»§ç»­æœªå®Œæˆ
```

**æ£€æŸ¥ç‚¹é€»è¾‘** (`run_multi_react.py:25-40`):

```python
def is_completed(output_file, question_id):
    if not os.path.exists(output_file):
        return False

    with open(output_file, 'r') as f:
        for line in f:
            result = json.loads(line)
            if result.get('question_id') == question_id:
                return True
    return False
```

### 5.4 æ‰¹é‡å¤„ç†

#### å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†

```bash
# å‡è®¾æœ‰ 10,000 ä¸ªæŸ¥è¯¢
wc -l eval_data/large_dataset.jsonl
# 10000 eval_data/large_dataset.jsonl

# åˆ†æ‰¹å¤„ç†
python run_multi_react.py \
    --dataset eval_data/large_dataset.jsonl \
    --output outputs \
    --max_workers 20 \
    --roll_out_count 3
    # é¢„è®¡è€—æ—¶: 10,000 * 10 min / (20 workers * 3 rollouts) â‰ˆ 28 å°æ—¶
```

**ä¼˜åŒ–ç­–ç•¥**:

1. **å¢åŠ å¹¶å‘åº¦**
```bash
# ä½¿ç”¨æ›´å¤š GPU
--max_workers 50

# æˆ–ä½¿ç”¨ OpenRouter (æ—  GPU é™åˆ¶)
```

2. **å‡å°‘ Rollout**
```bash
# é¦–æ¬¡è¿è¡Œç”¨ 1 æ¬¡
--roll_out_count 1

# å¯¹é‡è¦æ ·æœ¬å†è¿è¡Œ 3 æ¬¡
```

3. **åˆ†å¸ƒå¼å¤„ç†**
```bash
# èŠ‚ç‚¹ 1 å¤„ç†å‰ 5000
python run_multi_react.py \
    --dataset eval_data/large_dataset.jsonl \
    --output outputs_node1 \
    --total_splits 2 \
    --worker_split 1

# èŠ‚ç‚¹ 2 å¤„ç†å 5000
python run_multi_react.py \
    --dataset eval_data/large_dataset.jsonl \
    --output outputs_node2 \
    --total_splits 2 \
    --worker_split 2

# åˆå¹¶ç»“æœ
cat outputs_node1/*.jsonl outputs_node2/*.jsonl > outputs/merged.jsonl
```

---

## 6. é«˜çº§åŠŸèƒ½

### 6.1 è‡ªå®šä¹‰å·¥å…·

#### æ­¥éª¤ 1: åˆ›å»ºå·¥å…·ç±»

åˆ›å»º `inference/tool_database.py`:

```python
from qwen_agent.tools import BaseTool, register_tool
import json
import sqlite3

@register_tool('database_query')
class DatabaseQuery(BaseTool):
    """æŸ¥è¯¢ SQLite æ•°æ®åº“"""

    description = 'æ‰§è¡Œ SQL æŸ¥è¯¢å¹¶è¿”å›ç»“æœ'
    parameters = [{
        'name': 'query',
        'type': 'string',
        'description': 'SQL æŸ¥è¯¢è¯­å¥',
        'required': True
    }, {
        'name': 'database',
        'type': 'string',
        'description': 'æ•°æ®åº“æ–‡ä»¶è·¯å¾„',
        'required': True
    }]

    def call(self, params: str, **kwargs) -> str:
        try:
            # è§£æå‚æ•°
            params_dict = json.loads(params)
            query = params_dict['query']
            db_path = params_dict['database']

            # è¿æ¥æ•°æ®åº“
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()

            # æ‰§è¡ŒæŸ¥è¯¢
            cursor.execute(query)
            results = cursor.fetchall()

            # æ ¼å¼åŒ–è¾“å‡º
            output = f"æŸ¥è¯¢: {query}\n\n"
            output += "ç»“æœ:\n"
            for row in results:
                output += f"  {row}\n"

            conn.close()
            return output

        except Exception as e:
            return f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {str(e)}"
```

#### æ­¥éª¤ 2: æ³¨å†Œå·¥å…·

ç¼–è¾‘ `inference/react_agent.py`:

```python
# ç¬¬ 20 è¡Œ: å¯¼å…¥æ–°å·¥å…·
from tool_database import DatabaseQuery

# ç¬¬ 31-38 è¡Œ: æ·»åŠ åˆ°å·¥å…·åˆ—è¡¨
TOOL_CLASS = [
    FileParser(),
    Scholar(),
    Visit(),
    Search(),
    PythonInterpreter(),
    DatabaseQuery(),  # æ–°å¢
]
```

#### æ­¥éª¤ 3: æ›´æ–°æç¤ºè¯

ç¼–è¾‘ `inference/prompt.py`:

```python
SYSTEM_PROMPT = """
...
<tools>
...
{"type": "function", "function": {
    "name": "database_query",
    "description": "æ‰§è¡Œ SQL æŸ¥è¯¢å¹¶è¿”å›ç»“æœ",
    "parameters": {
        "type": "object",
        "properties": {
            "query": {"type": "string", "description": "SQL æŸ¥è¯¢è¯­å¥"},
            "database": {"type": "string", "description": "æ•°æ®åº“æ–‡ä»¶è·¯å¾„"}
        },
        "required": ["query", "database"]
    }
}}
</tools>
"""
```

#### æ­¥éª¤ 4: æµ‹è¯•æ–°å·¥å…·

```bash
# åˆ›å»ºæµ‹è¯•æ•°æ®åº“
sqlite3 test.db << EOF
CREATE TABLE users (id INTEGER, name TEXT, age INTEGER);
INSERT INTO users VALUES (1, 'Alice', 30);
INSERT INTO users VALUES (2, 'Bob', 25);
EOF

# åˆ›å»ºæŸ¥è¯¢
cat > eval_data/db_query.jsonl << EOF
{"question": "æŸ¥è¯¢ test.db æ•°æ®åº“ä¸­æ‰€æœ‰ç”¨æˆ·çš„å§“åå’Œå¹´é¾„", "answer": ""}
EOF

# è¿è¡Œæ¨ç†
python inference/run_multi_react.py \
    --model $MODEL_PATH \
    --dataset eval_data/db_query.jsonl \
    --output outputs
```

### 6.2 è‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡

#### åˆ›å»ºè‡ªå®šä¹‰è¯„ä¼°è„šæœ¬

åˆ›å»º `evaluation/custom_evaluator.py`:

```python
import json
import os
from openai import OpenAI

def evaluate_tool_efficiency(results_file):
    """è¯„ä¼°å·¥å…·ä½¿ç”¨æ•ˆç‡"""

    with open(results_file, 'r') as f:
        results = [json.loads(line) for line in f]

    metrics = {
        'total_samples': len(results),
        'avg_turns': 0,
        'avg_tools_per_sample': 0,
        'tool_distribution': {},
        'success_rate': 0
    }

    total_turns = 0
    total_tools = 0
    successful = 0

    for result in results:
        messages = result['messages']
        turns = len([m for m in messages if m['role'] == 'assistant'])
        total_turns += turns

        # ç»Ÿè®¡å·¥å…·è°ƒç”¨
        tools_used = []
        for msg in messages:
            if '<tool_call>' in msg.get('content', ''):
                # æå–å·¥å…·åç§°
                tool_name = extract_tool_name(msg['content'])
                tools_used.append(tool_name)
                total_tools += 1

        # æ›´æ–°å·¥å…·åˆ†å¸ƒ
        for tool in tools_used:
            metrics['tool_distribution'][tool] = \
                metrics['tool_distribution'].get(tool, 0) + 1

        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        if result['termination'] == 'answer':
            successful += 1

    metrics['avg_turns'] = total_turns / len(results)
    metrics['avg_tools_per_sample'] = total_tools / len(results)
    metrics['success_rate'] = successful / len(results)

    return metrics

def evaluate_answer_quality(results_file, reference_file):
    """ä½¿ç”¨ LLM è¯„åˆ¤ç­”æ¡ˆè´¨é‡"""

    # åŠ è½½ç»“æœå’Œå‚è€ƒç­”æ¡ˆ
    with open(results_file, 'r') as f:
        results = [json.loads(line) for line in f]

    with open(reference_file, 'r') as f:
        references = [json.loads(line) for line in f]

    # åˆ›å»ºè¯„åˆ¤æç¤ºè¯
    JUDGE_PROMPT = """
    è¯·è¯„ä¼°ä»¥ä¸‹ç­”æ¡ˆçš„è´¨é‡:

    é—®é¢˜: {question}
    å‚è€ƒç­”æ¡ˆ: {reference}
    æ¨¡å‹ç­”æ¡ˆ: {prediction}

    ä»ä»¥ä¸‹ç»´åº¦è¯„åˆ† (1-5):
    1. å‡†ç¡®æ€§ (Accuracy): ä¿¡æ¯æ˜¯å¦æ­£ç¡®
    2. å®Œæ•´æ€§ (Completeness): æ˜¯å¦è¦†ç›–å…³é”®ç‚¹
    3. æ¸…æ™°åº¦ (Clarity): è¡¨è¾¾æ˜¯å¦æ¸…æ¥š
    4. ç›¸å…³æ€§ (Relevance): æ˜¯å¦åˆ‡é¢˜

    è¾“å‡º JSON:
    {
        "accuracy": 5,
        "completeness": 4,
        "clarity": 5,
        "relevance": 5,
        "overall": 4.75,
        "reasoning": "è¯„åˆ†ç†ç”±..."
    }
    """

    client = OpenAI(api_key=os.getenv('API_KEY'))

    scores = []
    for result, ref in zip(results, references):
        prompt = JUDGE_PROMPT.format(
            question=result['question'],
            reference=ref['answer'],
            prediction=result['prediction']
        )

        response = client.chat.completions.create(
            model='gpt-4',
            messages=[{'role': 'user', 'content': prompt}]
        )

        score = json.loads(response.choices[0].message.content)
        scores.append(score)

    # è®¡ç®—å¹³å‡åˆ†
    avg_scores = {
        'accuracy': sum(s['accuracy'] for s in scores) / len(scores),
        'completeness': sum(s['completeness'] for s in scores) / len(scores),
        'clarity': sum(s['clarity'] for s in scores) / len(scores),
        'relevance': sum(s['relevance'] for s in scores) / len(scores),
        'overall': sum(s['overall'] for s in scores) / len(scores)
    }

    return avg_scores, scores

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('--results', required=True)
    parser.add_argument('--references', required=True)
    args = parser.parse_args()

    # è¯„ä¼°æ•ˆç‡
    efficiency = evaluate_tool_efficiency(args.results)
    print("å·¥å…·ä½¿ç”¨æ•ˆç‡:")
    print(json.dumps(efficiency, indent=2, ensure_ascii=False))

    # è¯„ä¼°è´¨é‡
    avg_scores, detailed_scores = evaluate_answer_quality(
        args.results,
        args.references
    )
    print("\nç­”æ¡ˆè´¨é‡:")
    print(json.dumps(avg_scores, indent=2, ensure_ascii=False))
```

#### è¿è¡Œè‡ªå®šä¹‰è¯„ä¼°

```bash
python evaluation/custom_evaluator.py \
    --results outputs/test_questions_rollout_0.jsonl \
    --references eval_data/test_questions.jsonl
```

### 6.3 æç¤ºè¯ä¼˜åŒ–

#### Few-Shot ç¤ºä¾‹

åœ¨ç³»ç»Ÿæç¤ºè¯ä¸­æ·»åŠ ç¤ºä¾‹ï¼š

```python
SYSTEM_PROMPT = """
You are a deep research assistant...

# Examples

## Example 1: Multi-hop Reasoning

User: "è°æ˜¯ 2024 å¹´å›¾çµå¥–å¾—ä¸»çš„åšå£«å¯¼å¸ˆï¼Ÿ"